{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "(16024, 20, 20, 20, 4) (6800, 20, 20, 20, 4)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 20, 20, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 20, 20, 20, 64)    6976      \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 20, 20, 20, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 20, 20, 20, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 10, 10, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 10, 10, 16)    13840     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 10, 10, 10, 16)    6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 5, 5, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 5, 5, 5, 16)       6928      \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 5, 5, 5, 8)        3464      \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 5, 5, 5, 4)        868       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 2, 2, 4)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2, 2, 2, 4)        16        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 163,296\n",
      "Trainable params: 163,288\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "CNN: \n",
      "\n",
      "[[5091  176]\n",
      " [1123  410]] 0.81 0.62\n",
      "[[4998  158]\n",
      " [1215  429]] 0.8 0.62\n",
      "[[4930  202]\n",
      " [1201  467]] 0.79 0.62\n",
      "[[4874  189]\n",
      " [1259  478]] 0.79 0.62\n",
      "[[4785  205]\n",
      " [1297  513]] 0.78 0.62\n",
      "[[4703  208]\n",
      " [1358  531]] 0.77 0.62\n",
      "[[4608  262]\n",
      " [1340  590]] 0.76 0.63\n",
      "[[4443  342]\n",
      " [1313  702]] 0.76 0.64\n",
      "[[4337  312]\n",
      " [1413  738]] 0.75 0.64\n",
      "[[4262  325]\n",
      " [1393  820]] 0.75 0.65\n",
      "[[4130  362]\n",
      " [1432  876]] 0.74 0.65\n",
      "[[3984  448]\n",
      " [1401  967]] 0.73 0.65\n",
      "[[3850  466]\n",
      " [1426 1058]] 0.72 0.66\n",
      "[[3817  448]\n",
      " [1469 1066]] 0.72 0.66\n",
      "[[3764  484]\n",
      " [1453 1099]] 0.72 0.66\n",
      "[[3746  502]\n",
      " [1439 1113]] 0.71 0.66\n",
      "[[3837  433]\n",
      " [1466 1064]] 0.72 0.66\n",
      "[[3890  415]\n",
      " [1507  988]] 0.72 0.65\n",
      "[[3979  417]\n",
      " [1490  914]] 0.72 0.64\n",
      "[[4050  390]\n",
      " [1529  831]] 0.72 0.63\n",
      "\n",
      " BASELINE MODEL: \n",
      "\n",
      "[[5267    0]\n",
      " [1533    0]] 0.77 0.5\n",
      "[[5156    0]\n",
      " [1644    0]] 0.76 0.5\n",
      "[[5132    0]\n",
      " [1668    0]] 0.75 0.5\n",
      "[[5063    0]\n",
      " [1737    0]] 0.74 0.5\n",
      "[[4990    0]\n",
      " [1810    0]] 0.73 0.5\n",
      "[[4911    0]\n",
      " [1889    0]] 0.72 0.5\n",
      "[[4870    0]\n",
      " [1930    0]] 0.72 0.5\n",
      "[[4785    0]\n",
      " [2015    0]] 0.7 0.5\n",
      "[[4649    0]\n",
      " [2151    0]] 0.68 0.5\n",
      "[[4587    0]\n",
      " [2213    0]] 0.67 0.5\n",
      "[[4492    0]\n",
      " [2308    0]] 0.66 0.5\n",
      "[[4432    0]\n",
      " [2368    0]] 0.65 0.5\n",
      "[[4316    0]\n",
      " [2484    0]] 0.63 0.5\n",
      "[[4265    0]\n",
      " [2535    0]] 0.63 0.5\n",
      "[[4248    0]\n",
      " [2552    0]] 0.62 0.5\n",
      "[[4248    0]\n",
      " [2552    0]] 0.62 0.5\n",
      "[[4270    0]\n",
      " [2530    0]] 0.63 0.5\n",
      "[[4305    0]\n",
      " [2495    0]] 0.63 0.5\n",
      "[[4396    0]\n",
      " [2404    0]] 0.65 0.5\n",
      "[[4440    0]\n",
      " [2360    0]] 0.65 0.5\n",
      "\n",
      " RANDOM MODEL: \n",
      "\n",
      "[[2612 2655]\n",
      " [ 768  765]] 0.5 0.5\n",
      "[[2611 2545]\n",
      " [ 832  812]] 0.5 0.5\n",
      "[[2564 2568]\n",
      " [ 835  833]] 0.5 0.5\n",
      "[[2517 2546]\n",
      " [ 876  861]] 0.5 0.5\n",
      "[[2490 2500]\n",
      " [ 901  909]] 0.5 0.5\n",
      "[[2464 2447]\n",
      " [ 926  963]] 0.5 0.51\n",
      "[[2408 2462]\n",
      " [ 947  983]] 0.5 0.5\n",
      "[[2384 2401]\n",
      " [1029  986]] 0.5 0.49\n",
      "[[2340 2309]\n",
      " [1053 1098]] 0.51 0.51\n",
      "[[2343 2244]\n",
      " [1161 1052]] 0.5 0.49\n",
      "[[2200 2292]\n",
      " [1168 1140]] 0.49 0.49\n",
      "[[2227 2205]\n",
      " [1171 1197]] 0.5 0.5\n",
      "[[2171 2145]\n",
      " [1252 1232]] 0.5 0.5\n",
      "[[2172 2093]\n",
      " [1263 1272]] 0.51 0.51\n",
      "[[2081 2167]\n",
      " [1299 1253]] 0.49 0.49\n",
      "[[2155 2093]\n",
      " [1288 1264]] 0.5 0.5\n",
      "[[2097 2173]\n",
      " [1297 1233]] 0.49 0.49\n",
      "[[2138 2167]\n",
      " [1219 1276]] 0.5 0.5\n",
      "[[2190 2206]\n",
      " [1200 1204]] 0.5 0.5\n",
      "[[2204 2236]\n",
      " [1169 1191]] 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "\n",
    "structure_ids = []\n",
    "for line in open('./structures lists/structures human.txt', 'r'):\n",
    "    line = line.strip('\\n')\n",
    "    structure_ids.append(line)\n",
    "# for line in open('./structures lists/structures ecoli.txt', 'r'):\n",
    "#     line = line.strip('\\n')\n",
    "#     structure_ids.append(line)\n",
    "structure_ids.remove('4pkd')\n",
    "structure_ids.remove('1a9n')\n",
    "structure_ids.remove('2adc')\n",
    "random.shuffle(structure_ids)\n",
    "print(len(structure_ids))\n",
    "\n",
    "# X = []\n",
    "# Y = []\n",
    "# for structure_id in structure_ids:\n",
    "#     protein = np.load('../data/voxelized data 10x10x10/' + structure_id + '_protein.npy', mmap_mode='r')\n",
    "#     rna = np.load('../data/voxelized data 10x10x10/' + structure_id + '_rna.npy', mmap_mode='r')\n",
    "#     X.append(protein[:20])\n",
    "#     X.append(protein[-20:])\n",
    "#     # rna = list(map(sum, rna))\n",
    "#     Y.append(rna[:20])\n",
    "#     Y.append(rna[-20:])\n",
    "\n",
    "# X = np.concatenate(X)\n",
    "# Y = np.concatenate(Y)\n",
    "# Y[Y > 0] = 1\n",
    "\n",
    "# num_train = int(X.shape[0]*0.7)\n",
    "# X_train = X[:num_train]\n",
    "# Y_train = Y[:num_train]\n",
    "# X_test = X[num_train:]\n",
    "# Y_test = Y[num_train:]\n",
    "# print(X_train.shape, X_test.shape)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "num_train = int(len(structure_ids)*0.7)\n",
    "for i, structure_id in enumerate(structure_ids):\n",
    "    protein = np.load('../data/voxelized data 20x20x20/' + structure_id + '_protein.npy', mmap_mode='r')\n",
    "    rna = np.load('../data/voxelized data 20x20x20/' + structure_id + '_rna.npy', mmap_mode='r')\n",
    "    if i <= num_train:\n",
    "        X_train.append(protein[:50])\n",
    "        X_train.append(protein[-50:])\n",
    "        Y_train.append(rna[:50])\n",
    "        Y_train.append(rna[-50:])\n",
    "    else:\n",
    "        X_test.append(protein[:50])\n",
    "        X_test.append(protein[-50:])\n",
    "        Y_test.append(rna[:50])\n",
    "        Y_test.append(rna[-50:])\n",
    "#     na = 0\n",
    "#     pos = 0\n",
    "#     while (np.sum(rna[na]) > 0) and (na < len(rna)-1):\n",
    "#         pos +=1\n",
    "#         na +=1\n",
    "\n",
    "#     print(structure_id, pos, len(rna))\n",
    "#     if i <= num_train:\n",
    "#         if pos > len(rna)/2:\n",
    "#             X_train.append(protein)\n",
    "#             Y_train.append(rna)\n",
    "#         else:\n",
    "#             X_train.append(protein[:pos])\n",
    "#             X_train.append(protein[-pos:])\n",
    "#             Y_train.append(rna[:pos])\n",
    "#             Y_train.append(rna[-pos:])\n",
    "#     else:\n",
    "#         if pos > len(rna)/2:\n",
    "#             X_test.append(protein)\n",
    "#             Y_test.append(rna)\n",
    "#         else:\n",
    "#             X_test.append(protein[:pos])\n",
    "#             X_test.append(protein[-pos:])\n",
    "#             Y_test.append(rna[:pos])\n",
    "#             Y_test.append(rna[-pos:])\n",
    "\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "Y_train = np.concatenate(Y_train)\n",
    "Y_train[Y_train > 0] = 1\n",
    "\n",
    "X_test = np.concatenate(X_test)\n",
    "Y_test = np.concatenate(Y_test)\n",
    "Y_test[Y_test > 0] = 1\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "ins = tf.keras.layers.Input((20, 20, 20, 4))\n",
    "con1 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', activation='relu')(ins)\n",
    "con2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con1)\n",
    "con3 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con2)\n",
    "maxp1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con3)\n",
    "con4 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp1)\n",
    "con5 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con4)\n",
    "con6 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con5)\n",
    "maxp2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con6)\n",
    "con7 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp2)\n",
    "con8 = tf.keras.layers.Conv3D(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu')(con7)\n",
    "con9 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='same', activation='relu')(con8)\n",
    "maxp3 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con9)\n",
    "batch = tf.keras.layers.BatchNormalization()(maxp3)\n",
    "flat = tf.keras.layers.Flatten()(batch)\n",
    "dens2 = tf.keras.layers.Dense(units=256, activation='relu')(flat)\n",
    "drop2 = tf.keras.layers.Dropout(0.6)(dens2)\n",
    "outs = tf.keras.layers.Dense(units=20, activation='sigmoid')(drop2)\n",
    "model = tf.keras.models.Model(inputs=ins, outputs=outs)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.00001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, Y_train, validation_split=0.33, epochs=500, batch_size=200, callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "model_best = model\n",
    "model_best.load_weights(\"weights_best.hdf5\")\n",
    "# print(model.evaluate(X_test, Y_test, verbose=0, batch_size=100))\n",
    "# model_best.save('model_cnn_15_2.h5')\n",
    "Y_pred = model_best.predict(X_test, batch_size=200)\n",
    "\n",
    "#CNN\n",
    "Y_pred[Y_pred >= 0.5] = 1\n",
    "Y_pred[Y_pred < 0.5] = 0\n",
    "\n",
    "confusion_matrix = [sklearn.metrics.confusion_matrix(Y_test[:,i], Y_pred[:,i]) for i in range(20)]\n",
    "accuracy = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix]\n",
    "auc = [sklearn.metrics.roc_auc_score(Y_test[:,i], Y_pred[:,i]) for i in range(20)]\n",
    "\n",
    "print('CNN: \\n')\n",
    "for i in range(len(confusion_matrix)):\n",
    "    print(confusion_matrix[i], np.round(accuracy[i], 2), np.round(auc[i], 2))\n",
    "\n",
    "# baseline model\n",
    "# predict all zeros; at least 50% correct predictions because there are 1/2 of negative examples\n",
    "# (Yi_true = [0, 0, 0, 0, 0])\n",
    "# Y_pred_base = np.zeros(Y_test.shape)\n",
    "\n",
    "po = np.sum(Y_train, axis=0)/Y_train.shape[0]\n",
    "po[po >= 0.5] = 1\n",
    "po[po < 0.5] = 0\n",
    "\n",
    "Y_pred_base = np.tile(po, (Y_test.shape[0],1))\n",
    "Y_pred_base[Y_pred_base >= 0.5] = 1\n",
    "Y_pred_base[Y_pred_base < 0.5] = 0\n",
    "\n",
    "confusion_matrix_base = [sklearn.metrics.confusion_matrix(Y_test[:,i], Y_pred_base[:,i]) for i in range(20)]\n",
    "accuracy_base = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_base]\n",
    "auc_base = [sklearn.metrics.roc_auc_score(Y_test[:,i], Y_pred_base[:,i]) for i in range(20)]\n",
    "\n",
    "print(f'\\n BASELINE MODEL: \\n')\n",
    "for i in range(len(confusion_matrix_base)):\n",
    "    print(confusion_matrix_base[i], np.round(accuracy_base[i], 2), np.round(auc_base[i], 2))\n",
    "\n",
    "#random model\n",
    "Y_pred_random = np.random.random(Y_test.shape)\n",
    "Y_pred_random[Y_pred_random >= 0.5] = 1\n",
    "Y_pred_random[Y_pred_random < 0.5] = 0\n",
    "\n",
    "confusion_matrix_random = [sklearn.metrics.confusion_matrix(Y_test[:,i], Y_pred_random[:,i]) for i in range(20)]\n",
    "accuracy_random = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_random]\n",
    "auc_random = [sklearn.metrics.roc_auc_score(Y_test[:,i], Y_pred_random[:,i]) for i in range(20)]\n",
    "\n",
    "print(f'\\n RANDOM MODEL: \\n')\n",
    "for i in range(len(confusion_matrix_random)):\n",
    "    print(confusion_matrix_random[i], np.round(accuracy_random[i], 2), np.round(auc_random[i], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
