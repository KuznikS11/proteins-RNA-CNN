{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "51901 27760\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 10, 10, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 10, 10, 64)    5248      \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 10, 10, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 10, 10, 10, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 5, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 5, 5, 5, 32)       27680     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 5, 5, 5, 16)       13840     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 5, 5, 5, 16)       6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 2, 2, 2, 16)       6928      \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 2, 2, 2, 8)        3464      \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 2, 2, 2, 4)        868       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 1, 4)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 1, 1, 4)        16        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1280      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                10280     \n",
      "=================================================================\n",
      "Total params: 159,540\n",
      "Trainable params: 159,532\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "129/129 [==============================] - 21s 166ms/step - loss: 0.6936 - acc: 0.5387 - mean_squared_error: 0.2502\n",
      "Epoch 2/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.6923 - acc: 0.6082 - mean_squared_error: 0.2496\n",
      "Epoch 3/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.6913 - acc: 0.6350 - mean_squared_error: 0.2491\n",
      "Epoch 4/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.6901 - acc: 0.6421 - mean_squared_error: 0.2485\n",
      "Epoch 5/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.6873 - acc: 0.6356 - mean_squared_error: 0.2471\n",
      "Epoch 6/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.6814 - acc: 0.6312 - mean_squared_error: 0.2442\n",
      "Epoch 7/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.6745 - acc: 0.6366 - mean_squared_error: 0.2407\n",
      "Epoch 8/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.6669 - acc: 0.6456 - mean_squared_error: 0.2370\n",
      "Epoch 9/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.6589 - acc: 0.6596 - mean_squared_error: 0.2331\n",
      "Epoch 10/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.6517 - acc: 0.6760 - mean_squared_error: 0.2296\n",
      "Epoch 11/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.6456 - acc: 0.6894 - mean_squared_error: 0.2266\n",
      "Epoch 12/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.6398 - acc: 0.7011 - mean_squared_error: 0.2238\n",
      "Epoch 13/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.6341 - acc: 0.7115 - mean_squared_error: 0.2210\n",
      "Epoch 14/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.6285 - acc: 0.7202 - mean_squared_error: 0.2183\n",
      "Epoch 15/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.6235 - acc: 0.7268 - mean_squared_error: 0.2159\n",
      "Epoch 16/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.6191 - acc: 0.7309 - mean_squared_error: 0.2138\n",
      "Epoch 17/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.6142 - acc: 0.7363 - mean_squared_error: 0.2115\n",
      "Epoch 18/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.6097 - acc: 0.7404 - mean_squared_error: 0.2094\n",
      "Epoch 19/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.6056 - acc: 0.7432 - mean_squared_error: 0.2074\n",
      "Epoch 20/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.6016 - acc: 0.7457 - mean_squared_error: 0.2055\n",
      "Epoch 21/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5973 - acc: 0.7483 - mean_squared_error: 0.2035\n",
      "Epoch 22/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.5935 - acc: 0.7504 - mean_squared_error: 0.2017\n",
      "Epoch 23/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.5894 - acc: 0.7527 - mean_squared_error: 0.1998\n",
      "Epoch 24/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5855 - acc: 0.7547 - mean_squared_error: 0.1981\n",
      "Epoch 25/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5816 - acc: 0.7565 - mean_squared_error: 0.1962\n",
      "Epoch 26/500\n",
      "129/129 [==============================] - 19s 151ms/step - loss: 0.5774 - acc: 0.7584 - mean_squared_error: 0.1944\n",
      "Epoch 27/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.5749 - acc: 0.7588 - mean_squared_error: 0.1932\n",
      "Epoch 28/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5733 - acc: 0.7574 - mean_squared_error: 0.1925\n",
      "Epoch 29/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5700 - acc: 0.7586 - mean_squared_error: 0.1911\n",
      "Epoch 30/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5663 - acc: 0.7602 - mean_squared_error: 0.1894\n",
      "Epoch 31/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5648 - acc: 0.7591 - mean_squared_error: 0.1888\n",
      "Epoch 32/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5626 - acc: 0.7602 - mean_squared_error: 0.1878\n",
      "Epoch 33/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5607 - acc: 0.7602 - mean_squared_error: 0.1870\n",
      "Epoch 34/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5586 - acc: 0.7604 - mean_squared_error: 0.1861\n",
      "Epoch 35/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5569 - acc: 0.7604 - mean_squared_error: 0.1853\n",
      "Epoch 36/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5544 - acc: 0.7614 - mean_squared_error: 0.1842\n",
      "Epoch 37/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5522 - acc: 0.7620 - mean_squared_error: 0.1833\n",
      "Epoch 38/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5514 - acc: 0.7612 - mean_squared_error: 0.1830\n",
      "Epoch 39/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5503 - acc: 0.7612 - mean_squared_error: 0.1825\n",
      "Epoch 40/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5485 - acc: 0.7622 - mean_squared_error: 0.1817\n",
      "Epoch 41/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5464 - acc: 0.7633 - mean_squared_error: 0.1808\n",
      "Epoch 42/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5443 - acc: 0.7645 - mean_squared_error: 0.1799\n",
      "Epoch 43/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5455 - acc: 0.7620 - mean_squared_error: 0.1805\n",
      "Epoch 44/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5440 - acc: 0.7626 - mean_squared_error: 0.1798\n",
      "Epoch 45/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5434 - acc: 0.7624 - mean_squared_error: 0.1796\n",
      "Epoch 46/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5419 - acc: 0.7625 - mean_squared_error: 0.1790\n",
      "Epoch 47/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.5419 - acc: 0.7620 - mean_squared_error: 0.1790\n",
      "Epoch 48/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5399 - acc: 0.7631 - mean_squared_error: 0.1781\n",
      "Epoch 49/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5391 - acc: 0.7635 - mean_squared_error: 0.1778\n",
      "Epoch 50/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5388 - acc: 0.7626 - mean_squared_error: 0.1777\n",
      "Epoch 51/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.5390 - acc: 0.7622 - mean_squared_error: 0.1778\n",
      "Epoch 52/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5375 - acc: 0.7633 - mean_squared_error: 0.1771\n",
      "Epoch 53/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5358 - acc: 0.7648 - mean_squared_error: 0.1764\n",
      "Epoch 54/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.5341 - acc: 0.7661 - mean_squared_error: 0.1757\n",
      "Epoch 55/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5368 - acc: 0.7623 - mean_squared_error: 0.1769\n",
      "Epoch 56/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.5354 - acc: 0.7635 - mean_squared_error: 0.1763\n",
      "Epoch 57/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5336 - acc: 0.7647 - mean_squared_error: 0.1755\n",
      "Epoch 58/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5355 - acc: 0.7623 - mean_squared_error: 0.1764\n",
      "Epoch 59/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5339 - acc: 0.7633 - mean_squared_error: 0.1757\n",
      "Epoch 60/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.5326 - acc: 0.7646 - mean_squared_error: 0.1752\n",
      "Epoch 61/500\n",
      "129/129 [==============================] - 19s 143ms/step - loss: 0.5323 - acc: 0.7648 - mean_squared_error: 0.1750\n",
      "Epoch 62/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.5339 - acc: 0.7624 - mean_squared_error: 0.1757\n",
      "Epoch 63/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5327 - acc: 0.7630 - mean_squared_error: 0.1753\n",
      "Epoch 64/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5311 - acc: 0.7642 - mean_squared_error: 0.1746\n",
      "Epoch 65/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5292 - acc: 0.7655 - mean_squared_error: 0.1739\n",
      "Epoch 66/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5310 - acc: 0.7635 - mean_squared_error: 0.1746\n",
      "Epoch 67/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5324 - acc: 0.7624 - mean_squared_error: 0.1752\n",
      "Epoch 68/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.5310 - acc: 0.7632 - mean_squared_error: 0.1746\n",
      "Epoch 69/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.5302 - acc: 0.7638 - mean_squared_error: 0.1742\n",
      "Epoch 70/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5290 - acc: 0.7643 - mean_squared_error: 0.1738\n",
      "Epoch 71/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5292 - acc: 0.7643 - mean_squared_error: 0.1738\n",
      "Epoch 72/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5297 - acc: 0.7636 - mean_squared_error: 0.1741\n",
      "Epoch 73/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5292 - acc: 0.7633 - mean_squared_error: 0.1739\n",
      "Epoch 74/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5292 - acc: 0.7630 - mean_squared_error: 0.1740\n",
      "Epoch 75/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5281 - acc: 0.7641 - mean_squared_error: 0.1735\n",
      "Epoch 76/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5290 - acc: 0.7629 - mean_squared_error: 0.1739\n",
      "Epoch 77/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5281 - acc: 0.7632 - mean_squared_error: 0.1735\n",
      "Epoch 78/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5278 - acc: 0.7631 - mean_squared_error: 0.1734\n",
      "Epoch 79/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5273 - acc: 0.7635 - mean_squared_error: 0.1732\n",
      "Epoch 80/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5269 - acc: 0.7637 - mean_squared_error: 0.1731\n",
      "Epoch 81/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5256 - acc: 0.7646 - mean_squared_error: 0.1725\n",
      "Epoch 82/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5238 - acc: 0.7660 - mean_squared_error: 0.1718\n",
      "Epoch 83/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5267 - acc: 0.7631 - mean_squared_error: 0.1730\n",
      "Epoch 84/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.5260 - acc: 0.7634 - mean_squared_error: 0.1728\n",
      "Epoch 85/500\n",
      "129/129 [==============================] - 17s 129ms/step - loss: 0.5262 - acc: 0.7629 - mean_squared_error: 0.1729\n",
      "Epoch 86/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5248 - acc: 0.7645 - mean_squared_error: 0.1722\n",
      "Epoch 87/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.5250 - acc: 0.7641 - mean_squared_error: 0.1724\n",
      "Epoch 88/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5251 - acc: 0.7633 - mean_squared_error: 0.1725\n",
      "Epoch 89/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5258 - acc: 0.7626 - mean_squared_error: 0.1728\n",
      "Epoch 90/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5255 - acc: 0.7630 - mean_squared_error: 0.1726\n",
      "Epoch 91/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5244 - acc: 0.7638 - mean_squared_error: 0.1722\n",
      "Epoch 92/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5236 - acc: 0.7642 - mean_squared_error: 0.1719\n",
      "Epoch 93/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5227 - acc: 0.7649 - mean_squared_error: 0.1715\n",
      "Epoch 94/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5218 - acc: 0.7654 - mean_squared_error: 0.1711\n",
      "Epoch 95/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5241 - acc: 0.7629 - mean_squared_error: 0.1721\n",
      "Epoch 96/500\n",
      "129/129 [==============================] - 17s 136ms/step - loss: 0.5229 - acc: 0.7640 - mean_squared_error: 0.1716\n",
      "Epoch 97/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5203 - acc: 0.7661 - mean_squared_error: 0.1706\n",
      "Epoch 98/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5229 - acc: 0.7632 - mean_squared_error: 0.1717\n",
      "Epoch 99/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5227 - acc: 0.7634 - mean_squared_error: 0.1716\n",
      "Epoch 100/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.5225 - acc: 0.7635 - mean_squared_error: 0.1716\n",
      "Epoch 101/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5228 - acc: 0.7628 - mean_squared_error: 0.1717\n",
      "Epoch 102/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5220 - acc: 0.7631 - mean_squared_error: 0.1714\n",
      "Epoch 103/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5212 - acc: 0.7640 - mean_squared_error: 0.1711\n",
      "Epoch 104/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5201 - acc: 0.7648 - mean_squared_error: 0.1706\n",
      "Epoch 105/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5183 - acc: 0.7660 - mean_squared_error: 0.1699\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5184 - acc: 0.7665 - mean_squared_error: 0.1699\n",
      "Epoch 107/500\n",
      "129/129 [==============================] - 19s 148ms/step - loss: 0.5205 - acc: 0.7636 - mean_squared_error: 0.1709\n",
      "Epoch 108/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5205 - acc: 0.7633 - mean_squared_error: 0.1709\n",
      "Epoch 109/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5201 - acc: 0.7634 - mean_squared_error: 0.1708\n",
      "Epoch 110/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5202 - acc: 0.7633 - mean_squared_error: 0.1708\n",
      "Epoch 111/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5196 - acc: 0.7638 - mean_squared_error: 0.1705\n",
      "Epoch 112/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.5196 - acc: 0.7633 - mean_squared_error: 0.1706\n",
      "Epoch 113/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.5170 - acc: 0.7654 - mean_squared_error: 0.1695\n",
      "Epoch 114/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5152 - acc: 0.7663 - mean_squared_error: 0.1688\n",
      "Epoch 115/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5138 - acc: 0.7674 - mean_squared_error: 0.1682\n",
      "Epoch 116/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5178 - acc: 0.7638 - mean_squared_error: 0.1700\n",
      "Epoch 117/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5180 - acc: 0.7638 - mean_squared_error: 0.1700\n",
      "Epoch 118/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5178 - acc: 0.7635 - mean_squared_error: 0.1700\n",
      "Epoch 119/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5173 - acc: 0.7638 - mean_squared_error: 0.1698\n",
      "Epoch 120/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.5184 - acc: 0.7628 - mean_squared_error: 0.1703\n",
      "Epoch 121/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5173 - acc: 0.7635 - mean_squared_error: 0.1698\n",
      "Epoch 122/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5159 - acc: 0.7646 - mean_squared_error: 0.1692\n",
      "Epoch 123/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5143 - acc: 0.7657 - mean_squared_error: 0.1686\n",
      "Epoch 124/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.5155 - acc: 0.7640 - mean_squared_error: 0.1692\n",
      "Epoch 125/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5161 - acc: 0.7636 - mean_squared_error: 0.1694\n",
      "Epoch 126/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5155 - acc: 0.7640 - mean_squared_error: 0.1692\n",
      "Epoch 127/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5141 - acc: 0.7655 - mean_squared_error: 0.1686\n",
      "Epoch 128/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5156 - acc: 0.7635 - mean_squared_error: 0.1693\n",
      "Epoch 129/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.5132 - acc: 0.7655 - mean_squared_error: 0.1683\n",
      "Epoch 130/500\n",
      "129/129 [==============================] - 17s 136ms/step - loss: 0.5136 - acc: 0.7648 - mean_squared_error: 0.1684\n",
      "Epoch 131/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5148 - acc: 0.7634 - mean_squared_error: 0.1690\n",
      "Epoch 132/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5138 - acc: 0.7639 - mean_squared_error: 0.1686\n",
      "Epoch 133/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5140 - acc: 0.7631 - mean_squared_error: 0.1688\n",
      "Epoch 134/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5133 - acc: 0.7637 - mean_squared_error: 0.1685\n",
      "Epoch 135/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5118 - acc: 0.7655 - mean_squared_error: 0.1678\n",
      "Epoch 136/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.5093 - acc: 0.7669 - mean_squared_error: 0.1668\n",
      "Epoch 137/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5106 - acc: 0.7662 - mean_squared_error: 0.1673\n",
      "Epoch 138/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5124 - acc: 0.7637 - mean_squared_error: 0.1682\n",
      "Epoch 139/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5122 - acc: 0.7635 - mean_squared_error: 0.1682\n",
      "Epoch 140/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5113 - acc: 0.7638 - mean_squared_error: 0.1678\n",
      "Epoch 141/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5124 - acc: 0.7630 - mean_squared_error: 0.1683\n",
      "Epoch 142/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5115 - acc: 0.7639 - mean_squared_error: 0.1679\n",
      "Epoch 143/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5099 - acc: 0.7648 - mean_squared_error: 0.1672\n",
      "Epoch 144/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5087 - acc: 0.7657 - mean_squared_error: 0.1668\n",
      "Epoch 145/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5088 - acc: 0.7657 - mean_squared_error: 0.1668\n",
      "Epoch 146/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.5107 - acc: 0.7635 - mean_squared_error: 0.1677\n",
      "Epoch 147/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5096 - acc: 0.7639 - mean_squared_error: 0.1672\n",
      "Epoch 148/500\n",
      "129/129 [==============================] - 19s 148ms/step - loss: 0.5093 - acc: 0.7640 - mean_squared_error: 0.1671\n",
      "Epoch 149/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5096 - acc: 0.7633 - mean_squared_error: 0.1673\n",
      "Epoch 150/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5098 - acc: 0.7630 - mean_squared_error: 0.1674\n",
      "Epoch 151/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.5092 - acc: 0.7633 - mean_squared_error: 0.1672\n",
      "Epoch 152/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5084 - acc: 0.7638 - mean_squared_error: 0.1669\n",
      "Epoch 153/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.5075 - acc: 0.7643 - mean_squared_error: 0.1665\n",
      "Epoch 154/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5067 - acc: 0.7648 - mean_squared_error: 0.1662\n",
      "Epoch 155/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5055 - acc: 0.7656 - mean_squared_error: 0.1658\n",
      "Epoch 156/500\n",
      "129/129 [==============================] - 17s 136ms/step - loss: 0.5043 - acc: 0.7665 - mean_squared_error: 0.1652\n",
      "Epoch 157/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5050 - acc: 0.7657 - mean_squared_error: 0.1655\n",
      "Epoch 158/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.5069 - acc: 0.7635 - mean_squared_error: 0.1664\n",
      "Epoch 159/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5056 - acc: 0.7642 - mean_squared_error: 0.1659\n",
      "Epoch 160/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.5042 - acc: 0.7653 - mean_squared_error: 0.1653\n",
      "Epoch 161/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5060 - acc: 0.7637 - mean_squared_error: 0.1661\n",
      "Epoch 162/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.5051 - acc: 0.7643 - mean_squared_error: 0.1657\n",
      "Epoch 163/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.5054 - acc: 0.7640 - mean_squared_error: 0.1659\n",
      "Epoch 164/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5049 - acc: 0.7640 - mean_squared_error: 0.1657\n",
      "Epoch 165/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5050 - acc: 0.7638 - mean_squared_error: 0.1658\n",
      "Epoch 166/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.5039 - acc: 0.7645 - mean_squared_error: 0.1653\n",
      "Epoch 167/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5033 - acc: 0.7650 - mean_squared_error: 0.1651\n",
      "Epoch 168/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5037 - acc: 0.7642 - mean_squared_error: 0.1653\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 17s 134ms/step - loss: 0.5044 - acc: 0.7637 - mean_squared_error: 0.1656\n",
      "Epoch 170/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5030 - acc: 0.7647 - mean_squared_error: 0.1650\n",
      "Epoch 171/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5018 - acc: 0.7656 - mean_squared_error: 0.1645\n",
      "Epoch 172/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.5009 - acc: 0.7667 - mean_squared_error: 0.1642\n",
      "Epoch 173/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.5026 - acc: 0.7641 - mean_squared_error: 0.1649\n",
      "Epoch 174/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5016 - acc: 0.7645 - mean_squared_error: 0.1646\n",
      "Epoch 175/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.5019 - acc: 0.7643 - mean_squared_error: 0.1647\n",
      "Epoch 176/500\n",
      "129/129 [==============================] - 19s 149ms/step - loss: 0.5014 - acc: 0.7644 - mean_squared_error: 0.1645\n",
      "Epoch 177/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.5020 - acc: 0.7637 - mean_squared_error: 0.1647\n",
      "Epoch 178/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4999 - acc: 0.7650 - mean_squared_error: 0.1640\n",
      "Epoch 179/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4999 - acc: 0.7652 - mean_squared_error: 0.1639\n",
      "Epoch 180/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.5004 - acc: 0.7643 - mean_squared_error: 0.1642\n",
      "Epoch 181/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.5011 - acc: 0.7639 - mean_squared_error: 0.1645\n",
      "Epoch 182/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4994 - acc: 0.7649 - mean_squared_error: 0.1638\n",
      "Epoch 183/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4977 - acc: 0.7665 - mean_squared_error: 0.1631\n",
      "Epoch 184/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4963 - acc: 0.7676 - mean_squared_error: 0.1625\n",
      "Epoch 185/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4999 - acc: 0.7639 - mean_squared_error: 0.1640\n",
      "Epoch 186/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4984 - acc: 0.7650 - mean_squared_error: 0.1635\n",
      "Epoch 187/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4970 - acc: 0.7662 - mean_squared_error: 0.1629\n",
      "Epoch 188/500\n",
      "129/129 [==============================] - 19s 148ms/step - loss: 0.4993 - acc: 0.7638 - mean_squared_error: 0.1639\n",
      "Epoch 189/500\n",
      "129/129 [==============================] - 19s 149ms/step - loss: 0.4979 - acc: 0.7650 - mean_squared_error: 0.1633\n",
      "Epoch 190/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4964 - acc: 0.7662 - mean_squared_error: 0.1627\n",
      "Epoch 191/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4964 - acc: 0.7661 - mean_squared_error: 0.1627\n",
      "Epoch 192/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4982 - acc: 0.7638 - mean_squared_error: 0.1635s - loss: 0.4994 - ac\n",
      "Epoch 193/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4970 - acc: 0.7644 - mean_squared_error: 0.1631\n",
      "Epoch 194/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4956 - acc: 0.7657 - mean_squared_error: 0.1625\n",
      "Epoch 195/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4942 - acc: 0.7669 - mean_squared_error: 0.1619\n",
      "Epoch 196/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4958 - acc: 0.7649 - mean_squared_error: 0.1626\n",
      "Epoch 197/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4971 - acc: 0.7640 - mean_squared_error: 0.1631\n",
      "Epoch 198/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4959 - acc: 0.7646 - mean_squared_error: 0.1627\n",
      "Epoch 199/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4949 - acc: 0.7654 - mean_squared_error: 0.1622\n",
      "Epoch 200/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4936 - acc: 0.7657 - mean_squared_error: 0.1618\n",
      "Epoch 201/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4940 - acc: 0.7658 - mean_squared_error: 0.1619\n",
      "Epoch 202/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4943 - acc: 0.7650 - mean_squared_error: 0.1621\n",
      "Epoch 203/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4943 - acc: 0.7647 - mean_squared_error: 0.1621\n",
      "Epoch 204/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4946 - acc: 0.7643 - mean_squared_error: 0.1622\n",
      "Epoch 205/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4932 - acc: 0.7655 - mean_squared_error: 0.1617\n",
      "Epoch 206/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4941 - acc: 0.7643 - mean_squared_error: 0.1621\n",
      "Epoch 207/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.4936 - acc: 0.7647 - mean_squared_error: 0.1619\n",
      "Epoch 208/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4935 - acc: 0.7647 - mean_squared_error: 0.1618\n",
      "Epoch 209/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.4927 - acc: 0.7652 - mean_squared_error: 0.1615\n",
      "Epoch 210/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4923 - acc: 0.7652 - mean_squared_error: 0.1614\n",
      "Epoch 211/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4908 - acc: 0.7662 - mean_squared_error: 0.1608\n",
      "Epoch 212/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4899 - acc: 0.7677 - mean_squared_error: 0.1604\n",
      "Epoch 213/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4919 - acc: 0.7648 - mean_squared_error: 0.1613\n",
      "Epoch 214/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4917 - acc: 0.7648 - mean_squared_error: 0.1612\n",
      "Epoch 215/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4919 - acc: 0.7646 - mean_squared_error: 0.1613\n",
      "Epoch 216/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4904 - acc: 0.7662 - mean_squared_error: 0.1607\n",
      "Epoch 217/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4908 - acc: 0.7657 - mean_squared_error: 0.1609\n",
      "Epoch 218/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4910 - acc: 0.7649 - mean_squared_error: 0.1610\n",
      "Epoch 219/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4915 - acc: 0.7643 - mean_squared_error: 0.1612\n",
      "Epoch 220/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4912 - acc: 0.7647 - mean_squared_error: 0.1611\n",
      "Epoch 221/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.4902 - acc: 0.7655 - mean_squared_error: 0.1607\n",
      "Epoch 222/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4893 - acc: 0.7659 - mean_squared_error: 0.1604\n",
      "Epoch 223/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4883 - acc: 0.7668 - mean_squared_error: 0.1599\n",
      "Epoch 224/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4879 - acc: 0.7672 - mean_squared_error: 0.1598\n",
      "Epoch 225/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4898 - acc: 0.7647 - mean_squared_error: 0.1606\n",
      "Epoch 226/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4886 - acc: 0.7658 - mean_squared_error: 0.1601\n",
      "Epoch 227/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4861 - acc: 0.7680 - mean_squared_error: 0.1591\n",
      "Epoch 228/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4886 - acc: 0.7651 - mean_squared_error: 0.1602\n",
      "Epoch 229/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4882 - acc: 0.7653 - mean_squared_error: 0.1601\n",
      "Epoch 230/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4879 - acc: 0.7656 - mean_squared_error: 0.1599\n",
      "Epoch 231/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4885 - acc: 0.7648 - mean_squared_error: 0.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "129/129 [==============================] - 20s 152ms/step - loss: 0.4879 - acc: 0.7652 - mean_squared_error: 0.1600\n",
      "Epoch 233/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4870 - acc: 0.7660 - mean_squared_error: 0.1596\n",
      "Epoch 234/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4860 - acc: 0.7667 - mean_squared_error: 0.1592\n",
      "Epoch 235/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4845 - acc: 0.7680 - mean_squared_error: 0.1586\n",
      "Epoch 236/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4844 - acc: 0.7686 - mean_squared_error: 0.1585\n",
      "Epoch 237/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4863 - acc: 0.7657 - mean_squared_error: 0.1594\n",
      "Epoch 238/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4861 - acc: 0.7655 - mean_squared_error: 0.1594\n",
      "Epoch 239/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4860 - acc: 0.7656 - mean_squared_error: 0.1593\n",
      "Epoch 240/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4861 - acc: 0.7655 - mean_squared_error: 0.1594\n",
      "Epoch 241/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.4853 - acc: 0.7660 - mean_squared_error: 0.1591\n",
      "Epoch 242/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4854 - acc: 0.7654 - mean_squared_error: 0.1591\n",
      "Epoch 243/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4832 - acc: 0.7677 - mean_squared_error: 0.1582\n",
      "Epoch 244/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4819 - acc: 0.7687 - mean_squared_error: 0.1577\n",
      "Epoch 245/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.4808 - acc: 0.7697 - mean_squared_error: 0.1571\n",
      "Epoch 246/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4842 - acc: 0.7663 - mean_squared_error: 0.1587\n",
      "Epoch 247/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4842 - acc: 0.7662 - mean_squared_error: 0.1587\n",
      "Epoch 248/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4843 - acc: 0.7659 - mean_squared_error: 0.1587\n",
      "Epoch 249/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4835 - acc: 0.7662 - mean_squared_error: 0.1584\n",
      "Epoch 250/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4848 - acc: 0.7652 - mean_squared_error: 0.1590\n",
      "Epoch 251/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4840 - acc: 0.7659 - mean_squared_error: 0.1586\n",
      "Epoch 252/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4824 - acc: 0.7671 - mean_squared_error: 0.1580\n",
      "Epoch 253/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4813 - acc: 0.7682 - mean_squared_error: 0.1576\n",
      "Epoch 254/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4823 - acc: 0.7665 - mean_squared_error: 0.1580\n",
      "Epoch 255/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4825 - acc: 0.7662 - mean_squared_error: 0.1581\n",
      "Epoch 256/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4817 - acc: 0.7665 - mean_squared_error: 0.1579\n",
      "Epoch 257/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4814 - acc: 0.7680 - mean_squared_error: 0.1576\n",
      "Epoch 258/500\n",
      "129/129 [==============================] - 17s 128ms/step - loss: 0.4824 - acc: 0.7662 - mean_squared_error: 0.1581\n",
      "Epoch 259/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4801 - acc: 0.7683 - mean_squared_error: 0.1571\n",
      "Epoch 260/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4811 - acc: 0.7674 - mean_squared_error: 0.1576\n",
      "Epoch 261/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4825 - acc: 0.7663 - mean_squared_error: 0.1581\n",
      "Epoch 262/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4813 - acc: 0.7669 - mean_squared_error: 0.1576\n",
      "Epoch 263/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4820 - acc: 0.7659 - mean_squared_error: 0.1580\n",
      "Epoch 264/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4811 - acc: 0.7667 - mean_squared_error: 0.1576\n",
      "Epoch 265/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4792 - acc: 0.7681 - mean_squared_error: 0.1568\n",
      "Epoch 266/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4777 - acc: 0.7698 - mean_squared_error: 0.1562\n",
      "Epoch 267/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4788 - acc: 0.7690 - mean_squared_error: 0.1567\n",
      "Epoch 268/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4802 - acc: 0.7667 - mean_squared_error: 0.1573\n",
      "Epoch 269/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4800 - acc: 0.7666 - mean_squared_error: 0.1573\n",
      "Epoch 270/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4798 - acc: 0.7671 - mean_squared_error: 0.1571\n",
      "Epoch 271/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4809 - acc: 0.7663 - mean_squared_error: 0.1576\n",
      "Epoch 272/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4798 - acc: 0.7671 - mean_squared_error: 0.1571\n",
      "Epoch 273/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4786 - acc: 0.7680 - mean_squared_error: 0.1566\n",
      "Epoch 274/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4775 - acc: 0.7689 - mean_squared_error: 0.1562\n",
      "Epoch 275/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4778 - acc: 0.7687 - mean_squared_error: 0.1564\n",
      "Epoch 276/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4792 - acc: 0.7666 - mean_squared_error: 0.1570\n",
      "Epoch 277/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4784 - acc: 0.7674 - mean_squared_error: 0.1567\n",
      "Epoch 278/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4782 - acc: 0.7674 - mean_squared_error: 0.1566\n",
      "Epoch 279/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4788 - acc: 0.7668 - mean_squared_error: 0.1568\n",
      "Epoch 280/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4785 - acc: 0.7667 - mean_squared_error: 0.1568\n",
      "Epoch 281/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4781 - acc: 0.7669 - mean_squared_error: 0.1566\n",
      "Epoch 282/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4776 - acc: 0.7674 - mean_squared_error: 0.1564\n",
      "Epoch 283/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4769 - acc: 0.7680 - mean_squared_error: 0.1561\n",
      "Epoch 284/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4760 - acc: 0.7685 - mean_squared_error: 0.1557\n",
      "Epoch 285/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4748 - acc: 0.7692 - mean_squared_error: 0.1553\n",
      "Epoch 286/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4734 - acc: 0.7705 - mean_squared_error: 0.1547\n",
      "Epoch 287/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4750 - acc: 0.7697 - mean_squared_error: 0.1553\n",
      "Epoch 288/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4769 - acc: 0.7674 - mean_squared_error: 0.1561\n",
      "Epoch 289/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4757 - acc: 0.7680 - mean_squared_error: 0.1557\n",
      "Epoch 290/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4743 - acc: 0.7692 - mean_squared_error: 0.1551\n",
      "Epoch 291/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4762 - acc: 0.7677 - mean_squared_error: 0.1559\n",
      "Epoch 292/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4752 - acc: 0.7683 - mean_squared_error: 0.1555\n",
      "Epoch 293/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.4755 - acc: 0.7681 - mean_squared_error: 0.1556\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4752 - acc: 0.7681 - mean_squared_error: 0.1555\n",
      "Epoch 295/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4758 - acc: 0.7678 - mean_squared_error: 0.1558\n",
      "Epoch 296/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4746 - acc: 0.7686 - mean_squared_error: 0.1553\n",
      "Epoch 297/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4741 - acc: 0.7692 - mean_squared_error: 0.1551\n",
      "Epoch 298/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4742 - acc: 0.7682 - mean_squared_error: 0.1552\n",
      "Epoch 299/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4756 - acc: 0.7680 - mean_squared_error: 0.1557\n",
      "Epoch 300/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4744 - acc: 0.7692 - mean_squared_error: 0.1552\n",
      "Epoch 301/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4730 - acc: 0.7698 - mean_squared_error: 0.1547\n",
      "Epoch 302/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4725 - acc: 0.7707 - mean_squared_error: 0.1545\n",
      "Epoch 303/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4739 - acc: 0.7685 - mean_squared_error: 0.1551\n",
      "Epoch 304/500\n",
      "129/129 [==============================] - 20s 156ms/step - loss: 0.4733 - acc: 0.7689 - mean_squared_error: 0.1549\n",
      "Epoch 305/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4738 - acc: 0.7684 - mean_squared_error: 0.1552\n",
      "Epoch 306/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4736 - acc: 0.7687 - mean_squared_error: 0.1550\n",
      "Epoch 307/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4739 - acc: 0.7680 - mean_squared_error: 0.1552\n",
      "Epoch 308/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4725 - acc: 0.7694 - mean_squared_error: 0.1546\n",
      "Epoch 309/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4722 - acc: 0.7698 - mean_squared_error: 0.1545\n",
      "Epoch 310/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4728 - acc: 0.7690 - mean_squared_error: 0.1547\n",
      "Epoch 311/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4737 - acc: 0.7687 - mean_squared_error: 0.1551\n",
      "Epoch 312/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4724 - acc: 0.7697 - mean_squared_error: 0.1545\n",
      "Epoch 313/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4707 - acc: 0.7713 - mean_squared_error: 0.1538\n",
      "Epoch 314/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4695 - acc: 0.7725 - mean_squared_error: 0.1533\n",
      "Epoch 315/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4723 - acc: 0.7689 - mean_squared_error: 0.1546\n",
      "Epoch 316/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.4710 - acc: 0.7702 - mean_squared_error: 0.1540\n",
      "Epoch 317/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4698 - acc: 0.7713 - mean_squared_error: 0.1535\n",
      "Epoch 318/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4719 - acc: 0.7691 - mean_squared_error: 0.1544\n",
      "Epoch 319/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4705 - acc: 0.7703 - mean_squared_error: 0.1538\n",
      "Epoch 320/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4689 - acc: 0.7712 - mean_squared_error: 0.1533\n",
      "Epoch 321/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4693 - acc: 0.7712 - mean_squared_error: 0.1534\n",
      "Epoch 322/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4711 - acc: 0.7692 - mean_squared_error: 0.1541\n",
      "Epoch 323/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4696 - acc: 0.7701 - mean_squared_error: 0.1536\n",
      "Epoch 324/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4683 - acc: 0.7711 - mean_squared_error: 0.1530\n",
      "Epoch 325/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4675 - acc: 0.7724 - mean_squared_error: 0.1527\n",
      "Epoch 326/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4692 - acc: 0.7706 - mean_squared_error: 0.1534\n",
      "Epoch 327/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.4703 - acc: 0.7696 - mean_squared_error: 0.1539\n",
      "Epoch 328/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4691 - acc: 0.7704 - mean_squared_error: 0.1534\n",
      "Epoch 329/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4684 - acc: 0.7710 - mean_squared_error: 0.1531\n",
      "Epoch 330/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4675 - acc: 0.7718 - mean_squared_error: 0.1528\n",
      "Epoch 331/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4672 - acc: 0.7715 - mean_squared_error: 0.1527\n",
      "Epoch 332/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4677 - acc: 0.7709 - mean_squared_error: 0.1529\n",
      "Epoch 333/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4679 - acc: 0.7709 - mean_squared_error: 0.1530\n",
      "Epoch 334/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4680 - acc: 0.7705 - mean_squared_error: 0.1531\n",
      "Epoch 335/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4665 - acc: 0.7716 - mean_squared_error: 0.1525\n",
      "Epoch 336/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4678 - acc: 0.7708 - mean_squared_error: 0.1530\n",
      "Epoch 337/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4673 - acc: 0.7710 - mean_squared_error: 0.1528\n",
      "Epoch 338/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4676 - acc: 0.7709 - mean_squared_error: 0.1529\n",
      "Epoch 339/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4665 - acc: 0.7716 - mean_squared_error: 0.1525\n",
      "Epoch 340/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4660 - acc: 0.7718 - mean_squared_error: 0.1523\n",
      "Epoch 341/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4653 - acc: 0.7726 - mean_squared_error: 0.1519\n",
      "Epoch 342/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4643 - acc: 0.7736 - mean_squared_error: 0.1516\n",
      "Epoch 343/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4661 - acc: 0.7713 - mean_squared_error: 0.1524\n",
      "Epoch 344/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4659 - acc: 0.7714 - mean_squared_error: 0.1523\n",
      "Epoch 345/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4660 - acc: 0.7713 - mean_squared_error: 0.1524\n",
      "Epoch 346/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4647 - acc: 0.7730 - mean_squared_error: 0.1518\n",
      "Epoch 347/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4651 - acc: 0.7724 - mean_squared_error: 0.1519\n",
      "Epoch 348/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4655 - acc: 0.7717 - mean_squared_error: 0.1522\n",
      "Epoch 349/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4662 - acc: 0.7711 - mean_squared_error: 0.1525\n",
      "Epoch 350/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4658 - acc: 0.7717 - mean_squared_error: 0.1522\n",
      "Epoch 351/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4652 - acc: 0.7724 - mean_squared_error: 0.1520\n",
      "Epoch 352/500\n",
      "129/129 [==============================] - 19s 143ms/step - loss: 0.4644 - acc: 0.7732 - mean_squared_error: 0.1517\n",
      "Epoch 353/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4636 - acc: 0.7737 - mean_squared_error: 0.1513\n",
      "Epoch 354/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.4631 - acc: 0.7741 - mean_squared_error: 0.1512\n",
      "Epoch 355/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4649 - acc: 0.7720 - mean_squared_error: 0.1519\n",
      "Epoch 356/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.4638 - acc: 0.7730 - mean_squared_error: 0.1515\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4620 - acc: 0.7750 - mean_squared_error: 0.1507\n",
      "Epoch 358/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4641 - acc: 0.7722 - mean_squared_error: 0.1517\n",
      "Epoch 359/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4640 - acc: 0.7727 - mean_squared_error: 0.1516\n",
      "Epoch 360/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4637 - acc: 0.7732 - mean_squared_error: 0.1515\n",
      "Epoch 361/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.4647 - acc: 0.7723 - mean_squared_error: 0.1519\n",
      "Epoch 362/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4642 - acc: 0.7728 - mean_squared_error: 0.1517\n",
      "Epoch 363/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4633 - acc: 0.7733 - mean_squared_error: 0.1513\n",
      "Epoch 364/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4623 - acc: 0.7744 - mean_squared_error: 0.1509\n",
      "Epoch 365/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4614 - acc: 0.7756 - mean_squared_error: 0.1505\n",
      "Epoch 366/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4617 - acc: 0.7756 - mean_squared_error: 0.1506\n",
      "Epoch 367/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4629 - acc: 0.7736 - mean_squared_error: 0.1512\n",
      "Epoch 368/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4631 - acc: 0.7734 - mean_squared_error: 0.1513\n",
      "Epoch 369/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4628 - acc: 0.7734 - mean_squared_error: 0.1511\n",
      "Epoch 370/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4628 - acc: 0.7737 - mean_squared_error: 0.1511\n",
      "Epoch 371/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4619 - acc: 0.7742 - mean_squared_error: 0.1508\n",
      "Epoch 372/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4627 - acc: 0.7736 - mean_squared_error: 0.1511\n",
      "Epoch 373/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4601 - acc: 0.7760 - mean_squared_error: 0.1500\n",
      "Epoch 374/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4592 - acc: 0.7768 - mean_squared_error: 0.1497\n",
      "Epoch 375/500\n",
      "129/129 [==============================] - 19s 150ms/step - loss: 0.4579 - acc: 0.7782 - mean_squared_error: 0.1491\n",
      "Epoch 376/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4614 - acc: 0.7743 - mean_squared_error: 0.1507\n",
      "Epoch 377/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4607 - acc: 0.7748 - mean_squared_error: 0.1504\n",
      "Epoch 378/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4614 - acc: 0.7744 - mean_squared_error: 0.1506\n",
      "Epoch 379/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4604 - acc: 0.7749 - mean_squared_error: 0.1503\n",
      "Epoch 380/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4619 - acc: 0.7739 - mean_squared_error: 0.1508\n",
      "Epoch 381/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4608 - acc: 0.7747 - mean_squared_error: 0.1504\n",
      "Epoch 382/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4594 - acc: 0.7758 - mean_squared_error: 0.1499\n",
      "Epoch 383/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4582 - acc: 0.7772 - mean_squared_error: 0.1494\n",
      "Epoch 384/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4592 - acc: 0.7755 - mean_squared_error: 0.1499\n",
      "Epoch 385/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4596 - acc: 0.7756 - mean_squared_error: 0.1500\n",
      "Epoch 386/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4588 - acc: 0.7759 - mean_squared_error: 0.1497\n",
      "Epoch 387/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4585 - acc: 0.7766 - mean_squared_error: 0.1495\n",
      "Epoch 388/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4593 - acc: 0.7755 - mean_squared_error: 0.1499\n",
      "Epoch 389/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4571 - acc: 0.7775 - mean_squared_error: 0.1490\n",
      "Epoch 390/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4578 - acc: 0.7766 - mean_squared_error: 0.1493\n",
      "Epoch 391/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4588 - acc: 0.7757 - mean_squared_error: 0.1497\n",
      "Epoch 392/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4579 - acc: 0.7764 - mean_squared_error: 0.1494\n",
      "Epoch 393/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4588 - acc: 0.7756 - mean_squared_error: 0.1498\n",
      "Epoch 394/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4581 - acc: 0.7765 - mean_squared_error: 0.1494\n",
      "Epoch 395/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.4564 - acc: 0.7779 - mean_squared_error: 0.1487\n",
      "Epoch 396/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4552 - acc: 0.7795 - mean_squared_error: 0.1482\n",
      "Epoch 397/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4561 - acc: 0.7781 - mean_squared_error: 0.1486\n",
      "Epoch 398/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4571 - acc: 0.7767 - mean_squared_error: 0.1491\n",
      "Epoch 399/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4568 - acc: 0.7768 - mean_squared_error: 0.1491\n",
      "Epoch 400/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4568 - acc: 0.7774 - mean_squared_error: 0.1489\n",
      "Epoch 401/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4584 - acc: 0.7762 - mean_squared_error: 0.1495\n",
      "Epoch 402/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.4579 - acc: 0.7769 - mean_squared_error: 0.1493\n",
      "Epoch 403/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4563 - acc: 0.7779 - mean_squared_error: 0.1487\n",
      "Epoch 404/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4552 - acc: 0.7789 - mean_squared_error: 0.1483\n",
      "Epoch 405/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4555 - acc: 0.7784 - mean_squared_error: 0.1484\n",
      "Epoch 406/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4565 - acc: 0.7771 - mean_squared_error: 0.1489\n",
      "Epoch 407/500\n",
      "129/129 [==============================] - 19s 143ms/step - loss: 0.4558 - acc: 0.7776 - mean_squared_error: 0.1486\n",
      "Epoch 408/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4558 - acc: 0.7778 - mean_squared_error: 0.1486\n",
      "Epoch 409/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4562 - acc: 0.7771 - mean_squared_error: 0.1487\n",
      "Epoch 410/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4563 - acc: 0.7770 - mean_squared_error: 0.1488\n",
      "Epoch 411/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4558 - acc: 0.7775 - mean_squared_error: 0.1486s - loss: 0.4530 - \n",
      "Epoch 412/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4552 - acc: 0.7781 - mean_squared_error: 0.1483\n",
      "Epoch 413/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4549 - acc: 0.7785 - mean_squared_error: 0.1482\n",
      "Epoch 414/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4541 - acc: 0.7791 - mean_squared_error: 0.1479\n",
      "Epoch 415/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4530 - acc: 0.7799 - mean_squared_error: 0.1475\n",
      "Epoch 416/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4523 - acc: 0.7806 - mean_squared_error: 0.1472\n",
      "Epoch 417/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4538 - acc: 0.7801 - mean_squared_error: 0.1477\n",
      "Epoch 418/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4563 - acc: 0.7775 - mean_squared_error: 0.1487\n",
      "Epoch 419/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4551 - acc: 0.7782 - mean_squared_error: 0.1483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4536 - acc: 0.7799 - mean_squared_error: 0.1477\n",
      "Epoch 421/500\n",
      "129/129 [==============================] - 19s 145ms/step - loss: 0.4552 - acc: 0.7783 - mean_squared_error: 0.1484\n",
      "Epoch 422/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4540 - acc: 0.7791 - mean_squared_error: 0.1479\n",
      "Epoch 423/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4542 - acc: 0.7791 - mean_squared_error: 0.1480\n",
      "Epoch 424/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4538 - acc: 0.7793 - mean_squared_error: 0.1479\n",
      "Epoch 425/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4545 - acc: 0.7793 - mean_squared_error: 0.1481\n",
      "Epoch 426/500\n",
      "129/129 [==============================] - 19s 143ms/step - loss: 0.4531 - acc: 0.7801 - mean_squared_error: 0.1476\n",
      "Epoch 427/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4529 - acc: 0.7805 - mean_squared_error: 0.1475s - loss: 0.4547 - acc: 0.7789 - mean\n",
      "Epoch 428/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4529 - acc: 0.7800 - mean_squared_error: 0.1475\n",
      "Epoch 429/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4540 - acc: 0.7795 - mean_squared_error: 0.1479\n",
      "Epoch 430/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4528 - acc: 0.7804 - mean_squared_error: 0.1474\n",
      "Epoch 431/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4522 - acc: 0.7814 - mean_squared_error: 0.1472\n",
      "Epoch 432/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4511 - acc: 0.7818 - mean_squared_error: 0.1468\n",
      "Epoch 433/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4521 - acc: 0.7806 - mean_squared_error: 0.1473\n",
      "Epoch 434/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4518 - acc: 0.7807 - mean_squared_error: 0.1471\n",
      "Epoch 435/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4520 - acc: 0.7808 - mean_squared_error: 0.1471\n",
      "Epoch 436/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4517 - acc: 0.7810 - mean_squared_error: 0.1470\n",
      "Epoch 437/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4525 - acc: 0.7804 - mean_squared_error: 0.1473\n",
      "Epoch 438/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4510 - acc: 0.7814 - mean_squared_error: 0.1467\n",
      "Epoch 439/500\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 0.4509 - acc: 0.7820 - mean_squared_error: 0.1466\n",
      "Epoch 440/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4514 - acc: 0.7811 - mean_squared_error: 0.1469\n",
      "Epoch 441/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4523 - acc: 0.7806 - mean_squared_error: 0.1472\n",
      "Epoch 442/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4508 - acc: 0.7819 - mean_squared_error: 0.1467\n",
      "Epoch 443/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4496 - acc: 0.7833 - mean_squared_error: 0.1462\n",
      "Epoch 444/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4486 - acc: 0.7842 - mean_squared_error: 0.1458\n",
      "Epoch 445/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4514 - acc: 0.7811 - mean_squared_error: 0.1470\n",
      "Epoch 446/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4497 - acc: 0.7827 - mean_squared_error: 0.1463\n",
      "Epoch 447/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4491 - acc: 0.7831 - mean_squared_error: 0.1461\n",
      "Epoch 448/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4520 - acc: 0.7811 - mean_squared_error: 0.1471\n",
      "Epoch 449/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4502 - acc: 0.7823 - mean_squared_error: 0.1465\n",
      "Epoch 450/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4497 - acc: 0.7830 - mean_squared_error: 0.1462\n",
      "Epoch 451/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4490 - acc: 0.7832 - mean_squared_error: 0.1460\n",
      "Epoch 452/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4511 - acc: 0.7814 - mean_squared_error: 0.1468\n",
      "Epoch 453/500\n",
      "129/129 [==============================] - 19s 144ms/step - loss: 0.4497 - acc: 0.7821 - mean_squared_error: 0.1463\n",
      "Epoch 454/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4486 - acc: 0.7834 - mean_squared_error: 0.1458\n",
      "Epoch 455/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4478 - acc: 0.7844 - mean_squared_error: 0.1455\n",
      "Epoch 456/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4496 - acc: 0.7824 - mean_squared_error: 0.1463\n",
      "Epoch 457/500\n",
      "129/129 [==============================] - 19s 147ms/step - loss: 0.4508 - acc: 0.7820 - mean_squared_error: 0.1467\n",
      "Epoch 458/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4499 - acc: 0.7827 - mean_squared_error: 0.1464\n",
      "Epoch 459/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4490 - acc: 0.7834 - mean_squared_error: 0.1460\n",
      "Epoch 460/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4486 - acc: 0.7839 - mean_squared_error: 0.1458\n",
      "Epoch 461/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4480 - acc: 0.7842 - mean_squared_error: 0.1457\n",
      "Epoch 462/500\n",
      "129/129 [==============================] - 17s 136ms/step - loss: 0.4483 - acc: 0.7838 - mean_squared_error: 0.1458\n",
      "Epoch 463/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4485 - acc: 0.7836 - mean_squared_error: 0.1459\n",
      "Epoch 464/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4486 - acc: 0.7833 - mean_squared_error: 0.1460\n",
      "Epoch 465/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4475 - acc: 0.7844 - mean_squared_error: 0.1455\n",
      "Epoch 466/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4487 - acc: 0.7835 - mean_squared_error: 0.1460\n",
      "Epoch 467/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4489 - acc: 0.7839 - mean_squared_error: 0.1460\n",
      "Epoch 468/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4493 - acc: 0.7835 - mean_squared_error: 0.1461\n",
      "Epoch 469/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4489 - acc: 0.7839 - mean_squared_error: 0.1460\n",
      "Epoch 470/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4482 - acc: 0.7844 - mean_squared_error: 0.1457\n",
      "Epoch 471/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4473 - acc: 0.7850 - mean_squared_error: 0.1453\n",
      "Epoch 472/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4467 - acc: 0.7859 - mean_squared_error: 0.1451\n",
      "Epoch 473/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4486 - acc: 0.7839 - mean_squared_error: 0.1459\n",
      "Epoch 474/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4485 - acc: 0.7841 - mean_squared_error: 0.1458\n",
      "Epoch 475/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4485 - acc: 0.7841 - mean_squared_error: 0.1458\n",
      "Epoch 476/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4471 - acc: 0.7856 - mean_squared_error: 0.1452\n",
      "Epoch 477/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4476 - acc: 0.7850 - mean_squared_error: 0.1455\n",
      "Epoch 478/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4479 - acc: 0.7843 - mean_squared_error: 0.1456\n",
      "Epoch 479/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4489 - acc: 0.7840 - mean_squared_error: 0.1460\n",
      "Epoch 480/500\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.4482 - acc: 0.7847 - mean_squared_error: 0.1457\n",
      "Epoch 481/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4474 - acc: 0.7855 - mean_squared_error: 0.1454\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4468 - acc: 0.7860 - mean_squared_error: 0.1451\n",
      "Epoch 483/500\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.4460 - acc: 0.7866 - mean_squared_error: 0.1448\n",
      "Epoch 484/500\n",
      "129/129 [==============================] - 17s 130ms/step - loss: 0.4460 - acc: 0.7865 - mean_squared_error: 0.1448\n",
      "Epoch 485/500\n",
      "129/129 [==============================] - 18s 143ms/step - loss: 0.4473 - acc: 0.7853 - mean_squared_error: 0.1454\n",
      "Epoch 486/500\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 0.4461 - acc: 0.7861 - mean_squared_error: 0.1449\n",
      "Epoch 487/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4444 - acc: 0.7879 - mean_squared_error: 0.1442\n",
      "Epoch 488/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4465 - acc: 0.7859 - mean_squared_error: 0.1451\n",
      "Epoch 489/500\n",
      "129/129 [==============================] - 17s 131ms/step - loss: 0.4462 - acc: 0.7861 - mean_squared_error: 0.1450\n",
      "Epoch 490/500\n",
      "129/129 [==============================] - 17s 134ms/step - loss: 0.4463 - acc: 0.7863 - mean_squared_error: 0.1450\n",
      "Epoch 491/500\n",
      "129/129 [==============================] - 17s 135ms/step - loss: 0.4472 - acc: 0.7855 - mean_squared_error: 0.1453\n",
      "Epoch 492/500\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.4472 - acc: 0.7860 - mean_squared_error: 0.1453\n",
      "Epoch 493/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4458 - acc: 0.7869 - mean_squared_error: 0.1447\n",
      "Epoch 494/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4452 - acc: 0.7879 - mean_squared_error: 0.1445\n",
      "Epoch 495/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4439 - acc: 0.7885 - mean_squared_error: 0.1440\n",
      "Epoch 496/500\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 0.4439 - acc: 0.7885 - mean_squared_error: 0.1440\n",
      "Epoch 497/500\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 0.4452 - acc: 0.7872 - mean_squared_error: 0.1446\n",
      "Epoch 498/500\n",
      "129/129 [==============================] - 18s 142ms/step - loss: 0.4453 - acc: 0.7873 - mean_squared_error: 0.1446\n",
      "Epoch 499/500\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 0.4452 - acc: 0.7873 - mean_squared_error: 0.1445\n",
      "Epoch 500/500\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 0.4452 - acc: 0.7873 - mean_squared_error: 0.1446\n",
      "(27600, 40)\n",
      "(27600, 2, 2, 10)\n",
      "(27760, 2, 2, 10)\n",
      "CNN: \n",
      "\n",
      "level 0\n",
      "[[22202   897]\n",
      " [ 4052   449]] 0.82 0.53\n",
      "[[21788  1084]\n",
      " [ 4168   560]] 0.81 0.54\n",
      "[[23104   102]\n",
      " [ 4389     5]] 0.84 0.5\n",
      "[[22788   198]\n",
      " [ 4577    37]] 0.83 0.5\n",
      "level 1\n",
      "[[21948   820]\n",
      " [ 4335   497]] 0.81 0.53\n",
      "[[21648  1087]\n",
      " [ 4184   681]] 0.81 0.55\n",
      "[[22827   243]\n",
      " [ 4511    19]] 0.83 0.5\n",
      "[[22581   233]\n",
      " [ 4738    48]] 0.82 0.5\n",
      "level 2\n",
      "[[21572   915]\n",
      " [ 4483   630]] 0.8 0.54\n",
      "[[21235  1159]\n",
      " [ 4384   822]] 0.8 0.55\n",
      "[[22471   344]\n",
      " [ 4678   107]] 0.82 0.5\n",
      "[[22298   306]\n",
      " [ 4900    96]] 0.81 0.5\n",
      "level 3\n",
      "[[21225   837]\n",
      " [ 4818   720]] 0.8 0.55\n",
      "[[21039  1093]\n",
      " [ 4592   876]] 0.79 0.56\n",
      "[[22064   404]\n",
      " [ 4944   188]] 0.81 0.51\n",
      "[[21795   429]\n",
      " [ 5206   170]] 0.8 0.51\n",
      "level 4\n",
      "[[20564   974]\n",
      " [ 5239   823]] 0.77 0.55\n",
      "[[20496  1026]\n",
      " [ 5118   960]] 0.78 0.56\n",
      "[[21516   617]\n",
      " [ 5220   247]] 0.79 0.51\n",
      "[[21147   456]\n",
      " [ 5722   275]] 0.78 0.51\n",
      "level 5\n",
      "[[19699  1041]\n",
      " [ 5986   874]] 0.75 0.54\n",
      "[[19689  1209]\n",
      " [ 5557  1145]] 0.75 0.56\n",
      "[[20581   772]\n",
      " [ 5815   432]] 0.76 0.52\n",
      "[[20164   624]\n",
      " [ 6380   432]] 0.75 0.52\n",
      "level 6\n",
      "[[18877   985]\n",
      " [ 6780   958]] 0.72 0.54\n",
      "[[18759  1274]\n",
      " [ 6344  1223]] 0.72 0.55\n",
      "[[19484   950]\n",
      " [ 6602   564]] 0.73 0.52\n",
      "[[19092   801]\n",
      " [ 7098   609]] 0.71 0.52\n",
      "level 7\n",
      "[[18019  1215]\n",
      " [ 7328  1038]] 0.69 0.53\n",
      "[[17992  1164]\n",
      " [ 7367  1077]] 0.69 0.53\n",
      "[[18077  1542]\n",
      " [ 6899  1082]] 0.69 0.53\n",
      "[[18141  1027]\n",
      " [ 7520   912]] 0.69 0.53\n",
      "level 8\n",
      "[[16926  1904]\n",
      " [ 7336  1434]] 0.67 0.53\n",
      "[[17131  1513]\n",
      " [ 7741  1215]] 0.66 0.53\n",
      "[[17433  1645]\n",
      " [ 7391  1131]] 0.67 0.52\n",
      "[[17570   986]\n",
      " [ 8096   948]] 0.67 0.53\n",
      "level 9\n",
      "[[16872  1614]\n",
      " [ 8098  1016]] 0.65 0.51\n",
      "[[16543  1522]\n",
      " [ 8308  1227]] 0.64 0.52\n",
      "[[16969  1725]\n",
      " [ 7919   987]] 0.65 0.51\n",
      "[[16958  1143]\n",
      " [ 8607   892]] 0.65 0.52\n",
      "(27600, 2, 2, 10)\n",
      "\n",
      " BASELINE MODEL: \n",
      "\n",
      "level 0\n",
      "[[23099     0]\n",
      " [ 4501     0]] 0.84 0.5\n",
      "[[22872     0]\n",
      " [ 4728     0]] 0.83 0.5\n",
      "[[23206     0]\n",
      " [ 4394     0]] 0.84 0.5\n",
      "[[22986     0]\n",
      " [ 4614     0]] 0.83 0.5\n",
      "level 1\n",
      "[[22768     0]\n",
      " [ 4832     0]] 0.82 0.5\n",
      "[[22735     0]\n",
      " [ 4865     0]] 0.82 0.5\n",
      "[[23070     0]\n",
      " [ 4530     0]] 0.84 0.5\n",
      "[[22814     0]\n",
      " [ 4786     0]] 0.83 0.5\n",
      "level 2\n",
      "[[22487     0]\n",
      " [ 5113     0]] 0.81 0.5\n",
      "[[22394     0]\n",
      " [ 5206     0]] 0.81 0.5\n",
      "[[22815     0]\n",
      " [ 4785     0]] 0.83 0.5\n",
      "[[22604     0]\n",
      " [ 4996     0]] 0.82 0.5\n",
      "level 3\n",
      "[[22062     0]\n",
      " [ 5538     0]] 0.8 0.5\n",
      "[[22132     0]\n",
      " [ 5468     0]] 0.8 0.5\n",
      "[[22468     0]\n",
      " [ 5132     0]] 0.81 0.5\n",
      "[[22224     0]\n",
      " [ 5376     0]] 0.81 0.5\n",
      "level 4\n",
      "[[21538     0]\n",
      " [ 6062     0]] 0.78 0.5\n",
      "[[21522     0]\n",
      " [ 6078     0]] 0.78 0.5\n",
      "[[22133     0]\n",
      " [ 5467     0]] 0.8 0.5\n",
      "[[21603     0]\n",
      " [ 5997     0]] 0.78 0.5\n",
      "level 5\n",
      "[[20740     0]\n",
      " [ 6860     0]] 0.75 0.5\n",
      "[[20898     0]\n",
      " [ 6702     0]] 0.76 0.5\n",
      "[[21353     0]\n",
      " [ 6247     0]] 0.77 0.5\n",
      "[[20788     0]\n",
      " [ 6812     0]] 0.75 0.5\n",
      "level 6\n",
      "[[19862     0]\n",
      " [ 7738     0]] 0.72 0.5\n",
      "[[20033     0]\n",
      " [ 7567     0]] 0.73 0.5\n",
      "[[20434     0]\n",
      " [ 7166     0]] 0.74 0.5\n",
      "[[19893     0]\n",
      " [ 7707     0]] 0.72 0.5\n",
      "level 7\n",
      "[[19234     0]\n",
      " [ 8366     0]] 0.7 0.5\n",
      "[[19156     0]\n",
      " [ 8444     0]] 0.69 0.5\n",
      "[[19619     0]\n",
      " [ 7981     0]] 0.71 0.5\n",
      "[[19168     0]\n",
      " [ 8432     0]] 0.69 0.5\n",
      "level 8\n",
      "[[18830     0]\n",
      " [ 8770     0]] 0.68 0.5\n",
      "[[18644     0]\n",
      " [ 8956     0]] 0.68 0.5\n",
      "[[19078     0]\n",
      " [ 8522     0]] 0.69 0.5\n",
      "[[18556     0]\n",
      " [ 9044     0]] 0.67 0.5\n",
      "level 9\n",
      "[[18486     0]\n",
      " [ 9114     0]] 0.67 0.5\n",
      "[[18065     0]\n",
      " [ 9535     0]] 0.65 0.5\n",
      "[[18694     0]\n",
      " [ 8906     0]] 0.68 0.5\n",
      "[[18101     0]\n",
      " [ 9499     0]] 0.66 0.5\n",
      "\n",
      " RANDOM MODEL: \n",
      "\n",
      "level 0\n",
      "[[11546 11553]\n",
      " [ 2254  2247]] 0.5 0.5\n",
      "[[11380 11492]\n",
      " [ 2363  2365]] 0.5 0.5\n",
      "[[11578 11628]\n",
      " [ 2196  2198]] 0.5 0.5\n",
      "[[11421 11565]\n",
      " [ 2326  2288]] 0.5 0.5\n",
      "level 1\n",
      "[[11493 11275]\n",
      " [ 2388  2444]] 0.5 0.51\n",
      "[[11354 11381]\n",
      " [ 2369  2496]] 0.5 0.51\n",
      "[[11481 11589]\n",
      " [ 2282  2248]] 0.5 0.5\n",
      "[[11480 11334]\n",
      " [ 2392  2394]] 0.5 0.5\n",
      "level 2\n",
      "[[11396 11091]\n",
      " [ 2557  2556]] 0.51 0.5\n",
      "[[11257 11137]\n",
      " [ 2594  2612]] 0.5 0.5\n",
      "[[11418 11397]\n",
      " [ 2454  2331]] 0.5 0.49\n",
      "[[11211 11393]\n",
      " [ 2497  2499]] 0.5 0.5\n",
      "level 3\n",
      "[[11005 11057]\n",
      " [ 2796  2742]] 0.5 0.5\n",
      "[[11112 11020]\n",
      " [ 2673  2795]] 0.5 0.51\n",
      "[[11295 11173]\n",
      " [ 2502  2630]] 0.5 0.51\n",
      "[[11126 11098]\n",
      " [ 2648  2728]] 0.5 0.5\n",
      "level 4\n",
      "[[10858 10680]\n",
      " [ 3008  3054]] 0.5 0.5\n",
      "[[10723 10799]\n",
      " [ 3006  3072]] 0.5 0.5\n",
      "[[11083 11050]\n",
      " [ 2694  2773]] 0.5 0.5\n",
      "[[10850 10753]\n",
      " [ 2987  3010]] 0.5 0.5\n",
      "level 5\n",
      "[[10314 10426]\n",
      " [ 3393  3467]] 0.5 0.5\n",
      "[[10414 10484]\n",
      " [ 3381  3321]] 0.5 0.5\n",
      "[[10682 10671]\n",
      " [ 3128  3119]] 0.5 0.5\n",
      "[[10430 10358]\n",
      " [ 3459  3353]] 0.5 0.5\n",
      "level 6\n",
      "[[ 9808 10054]\n",
      " [ 3868  3870]] 0.5 0.5\n",
      "[[ 9965 10068]\n",
      " [ 3713  3854]] 0.5 0.5\n",
      "[[10304 10130]\n",
      " [ 3625  3541]] 0.5 0.5\n",
      "[[10099  9794]\n",
      " [ 3835  3872]] 0.51 0.51\n",
      "level 7\n",
      "[[9675 9559]\n",
      " [4180 4186]] 0.5 0.5\n",
      "[[9481 9675]\n",
      " [4172 4272]] 0.5 0.5\n",
      "[[9873 9746]\n",
      " [4014 3967]] 0.5 0.5\n",
      "[[9542 9626]\n",
      " [4142 4290]] 0.5 0.5\n",
      "level 8\n",
      "[[9505 9325]\n",
      " [4411 4359]] 0.5 0.5\n",
      "[[9480 9164]\n",
      " [4538 4418]] 0.5 0.5\n",
      "[[9560 9518]\n",
      " [4221 4301]] 0.5 0.5\n",
      "[[9253 9303]\n",
      " [4496 4548]] 0.5 0.5\n",
      "level 9\n",
      "[[9291 9195]\n",
      " [4540 4574]] 0.5 0.5\n",
      "[[9095 8970]\n",
      " [4860 4675]] 0.5 0.5\n",
      "[[9371 9323]\n",
      " [4421 4485]] 0.5 0.5\n",
      "[[9027 9074]\n",
      " [4775 4724]] 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "\n",
    "def generator(X, Y, batch_size=32, train=True):\n",
    "    while True:\n",
    "        for offset in range(0, len(X), batch_size):\n",
    "            X_batch = np.stack(X[offset:offset+batch_size], axis=0)\n",
    "            Y_batch = np.stack(Y[offset:offset+batch_size], axis=0)\n",
    "            \n",
    "            Y_batch_ = np.empty((Y_batch.shape[0], 2,2,10))\n",
    "            for m in range(Y_batch.shape[0]):\n",
    "                for i in range(10):\n",
    "                    Y_batch_[m, :,:,i] = [[np.sum(Y_batch[m, :5, :5, i]), np.sum(Y_batch[m, :5, 5:, i])], [np.sum(Y_batch[m, 5:, :5, i]), np.sum(Y_batch[m, 5:, 5:, i])]]\n",
    "            Y_batch_[Y_batch_ > 0] = 1\n",
    "\n",
    "            if train:\n",
    "                Y_f = np.array([Y_batch_[e].flatten() for e in range(Y_batch_.shape[0])])\n",
    "                yield (X_batch, Y_f)\n",
    "            else:\n",
    "                yield X_batch\n",
    "\n",
    "structure_ids = []\n",
    "for line in open('./structures lists/structures human.txt', 'r'):\n",
    "    line = line.strip('\\n')\n",
    "    structure_ids.append(line)\n",
    "# for line in open('./structures lists/structures ecoli.txt', 'r'):\n",
    "#     line = line.strip('\\n')\n",
    "#     structure_ids.append(line)\n",
    "structure_ids.remove('4pkd')\n",
    "structure_ids.remove('1a9n')\n",
    "structure_ids.remove('2adc')\n",
    "random.shuffle(structure_ids)\n",
    "print(len(structure_ids))\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "num_aa_train = 0\n",
    "num_aa_test = 0\n",
    "num_train = int(len(structure_ids)*0.7)\n",
    "for i, structure_id in enumerate(structure_ids):\n",
    "    protein = np.load('../data/voxelized data 10x10x10/' + structure_id + '_protein.npy', mmap_mode='r')\n",
    "    rna = np.load('../data/voxelized data 10x10x10/' + structure_id + '_rna_3D.npy', mmap_mode='r')\n",
    "    na = 0\n",
    "    pos = 0\n",
    "    while (np.sum(rna[na]) > 0) and (na < len(rna)-1):\n",
    "        pos +=1\n",
    "        na +=1\n",
    "    \n",
    "\n",
    "    if i <= num_train:\n",
    "        X_train.extend(protein[:pos, :, :, :, :3])\n",
    "        Y_train.extend(rna[:pos])\n",
    "        num_aa_train +=pos\n",
    "#         if pos > len(rna)/2:\n",
    "#             X_train.extend(protein[:, :, :, :, :3])\n",
    "#             Y_train.extend(rna)\n",
    "#             num_aa_train +=len(rna)\n",
    "#         else:\n",
    "#             X_train.extend(protein[:pos, :, :, :, :3])\n",
    "#             X_train.extend(protein[-pos:, :, :, :, :3])\n",
    "#             Y_train.extend(rna[:pos])\n",
    "#             Y_train.extend(rna[-pos:])\n",
    "#             num_aa_train +=2*pos\n",
    "    else:\n",
    "        X_test.extend(protein[:pos, :, :, :, :3])\n",
    "        Y_test.extend(rna[:pos])\n",
    "        num_aa_test +=pos\n",
    "#         if pos > len(rna)/2:\n",
    "#             X_test.extend(protein[:, :, :, :, :3])\n",
    "#             Y_test.extend(rna)\n",
    "#             num_aa_test +=len(rna)\n",
    "#         else:\n",
    "#             X_test.extend(protein[:pos, :, :, :, :3])\n",
    "#             X_test.extend(protein[-pos:, :, :, :, :3])\n",
    "#             Y_test.extend(rna[:pos])\n",
    "#             Y_test.extend(rna[-pos:])\n",
    "#             num_aa_test +=2*pos\n",
    "\n",
    "Y_test = np.stack(Y_test, axis=0)\n",
    "Y_test_ = np.empty((len(Y_test), 2,2,10))\n",
    "for m in range(len(Y_test)):\n",
    "    for i in range(10):\n",
    "        Y_test_[m, :,:,i] = [[np.sum(Y_test[m, :5, :5, i]), np.sum(Y_test[m, :5, 5:, i])], [np.sum(Y_test[m, 5:, :5, i]), np.sum(Y_test[m, 5:, 5:, i])]]\n",
    "Y_test_prob = Y_test_\n",
    "Y_test_[Y_test_ > 0] = 1\n",
    "   \n",
    "n_steps_train = int(num_aa_train/400) \n",
    "n_steps_test = int(num_aa_test/400)\n",
    "\n",
    "print(num_aa_train, num_aa_test)\n",
    "\n",
    "generator_train = generator(X_train, Y_train, 400, True)\n",
    "generator_test = generator(X_test, Y_test, 400, False)\n",
    "\n",
    "ins = tf.keras.layers.Input((10, 10, 10, 3))\n",
    "con1 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', activation='relu')(ins)\n",
    "con2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con1)\n",
    "con3 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con2)\n",
    "maxp1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con3)\n",
    "con4 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp1)\n",
    "con5 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con4)\n",
    "con6 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con5)\n",
    "maxp2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con6)\n",
    "con7 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp2)\n",
    "con8 = tf.keras.layers.Conv3D(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu')(con7)\n",
    "con9 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='same', activation='relu')(con8)\n",
    "maxp3 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con9)\n",
    "batch = tf.keras.layers.BatchNormalization()(maxp3)\n",
    "flat = tf.keras.layers.Flatten()(batch)\n",
    "dens2 = tf.keras.layers.Dense(units=256, activation='relu')(flat)\n",
    "drop2 = tf.keras.layers.Dropout(0.6)(dens2)\n",
    "outs = tf.keras.layers.Dense(units=40, activation='sigmoid')(drop2)\n",
    "model = tf.keras.models.Model(inputs=ins, outputs=outs)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.00001), metrics=['accuracy', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# checkpoint\n",
    "# filepath=\"weights_best.hdf5\"\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# model.fit(X_train, Y_train_f, validation_split=0.33, epochs=1, batch_size=200, callbacks=callbacks_list, verbose=0)\n",
    "model.fit_generator(generator_train, steps_per_epoch=n_steps_train, epochs=500, callbacks=None, verbose=1, max_queue_size=2)\n",
    "\n",
    "# model_best = model\n",
    "# model_best.load_weights(\"weights_best.hdf5\")\n",
    "# print(model.evaluate(X_test, Y_test, verbose=0, batch_size=100))\n",
    "# model_best.save('model_cnn_15_2.h5')\n",
    "# Y_pred = model_best.predict(X_test, batch_size=200)\n",
    "Y_pred = model.predict_generator(generator_test, steps=n_steps_test)\n",
    "print(Y_pred.shape)\n",
    "Y_pred_ = np.array([Y_pred[i].reshape((2,2,10)) for i in range(Y_pred.shape[0])])\n",
    "\n",
    "#CNN\n",
    "Y_pred_prob = Y_pred_\n",
    "Y_pred_[Y_pred_ >= 0.5] = 1\n",
    "Y_pred_[Y_pred_ < 0.5] = 0\n",
    "\n",
    "print(Y_pred_.shape)\n",
    "print(Y_test_.shape)\n",
    "Y_test_ = Y_test_[:Y_pred_.shape[0]]\n",
    "Y_test_prob = Y_test_prob[:Y_pred_.shape[0]]\n",
    "\n",
    "print('CNN: \\n')\n",
    "for i in range(10):\n",
    "    confusion_matrix = [sklearn.metrics.confusion_matrix(Y_test_[:,l , c, i], Y_pred_[:,l , c, i]) for l in range(2) for c in range(2)]\n",
    "    accuracy = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix]\n",
    "    auc = [sklearn.metrics.roc_auc_score(Y_test_prob[:,l , c, i], Y_pred_prob[:,l , c, i]) for l in range(2) for c in range(2)]\n",
    "\n",
    "    print(f'level {i}')\n",
    "    for q in range(len(confusion_matrix)):\n",
    "        print(confusion_matrix[q], np.round(accuracy[q], 2), np.round(auc[q], 2))\n",
    "\n",
    "# baseline model\n",
    "# predict all zeros; at least 50% correct predictions because there are 1/2 of negative examples\n",
    "Y_pred_base = np.zeros(Y_test_.shape)\n",
    "\n",
    "# po = np.sum(Y_train, axis=0)/Y_train.shape[0]\n",
    "# po[po >= 0.5] = 1\n",
    "# po[po < 0.5] = 0\n",
    "# Y_pred_base = np.tile(po, (Y_test.shape[0],1))\n",
    "\n",
    "print(Y_pred_base.shape)\n",
    "print(f'\\n BASELINE MODEL: \\n')\n",
    "for i in range(10):\n",
    "    confusion_matrix_base = [sklearn.metrics.confusion_matrix(Y_test_[:,l, c, i], Y_pred_base[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "    accuracy_base = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_base]\n",
    "    auc_base = [sklearn.metrics.roc_auc_score(Y_test_[:,l, c, i], Y_pred_base[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "    \n",
    "    print(f'level {i}')\n",
    "    for q in range(len(confusion_matrix_base)):\n",
    "        print(confusion_matrix_base[q], np.round(accuracy_base[q], 2), np.round(auc_base[q], 2))\n",
    "\n",
    "#random model\n",
    "Y_pred_random = np.random.random(Y_test_.shape)\n",
    "Y_pred_random[Y_pred_random >= 0.5] = 1\n",
    "Y_pred_random[Y_pred_random < 0.5] = 0\n",
    "\n",
    "print(f'\\n RANDOM MODEL: \\n')\n",
    "for i in range(10):\n",
    "    confusion_matrix_random = [sklearn.metrics.confusion_matrix(Y_test_[:,l, c, i], Y_pred_random[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "    accuracy_random = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_random]\n",
    "    auc_random = [sklearn.metrics.roc_auc_score(Y_test_[:,l, c, i], Y_pred_random[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "\n",
    "    print(f'level {i}')\n",
    "    for q in range(len(confusion_matrix_random)):\n",
    "        print(confusion_matrix_random[q], np.round(accuracy_random[q], 2), np.round(auc_random[q], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
