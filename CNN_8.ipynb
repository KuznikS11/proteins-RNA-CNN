{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "(6524, 7, 7, 7, 3) (2796, 7, 7, 7, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 7, 7, 7, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 7, 7, 7, 64)       5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 7, 7, 7, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 7, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 7, 7, 7, 32)       55328     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 7, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 3, 3, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 3, 3, 3, 16)       13840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 3, 3, 16)       64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 3, 3, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 3, 3, 8)        3464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 3, 8)        32        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 3, 8)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 1, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 1, 8)        32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              9216      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 94,783\n",
      "Trainable params: 94,527\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "CNN: \n",
      "\n",
      "[[1719  276]\n",
      " [ 481  320]] 0.7292560801144492\n",
      "[[1656  236]\n",
      " [ 551  353]] 0.7185264663805436\n",
      "[[1423  309]\n",
      " [ 553  511]] 0.6917024320457796\n",
      "[[1328  247]\n",
      " [ 572  649]] 0.7070815450643777\n",
      "[[1228  307]\n",
      " [ 491  770]] 0.7145922746781116\n",
      "[[1233  337]\n",
      " [ 421  805]] 0.728898426323319\n",
      "[[1308  355]\n",
      " [ 407  726]] 0.7274678111587983\n",
      "\n",
      " BASELINE MODEL: \n",
      "\n",
      "[[1995    0]\n",
      " [ 801    0]] 0.7135193133047211\n",
      "[[1892    0]\n",
      " [ 904    0]] 0.6766809728183119\n",
      "[[1732    0]\n",
      " [1064    0]] 0.6194563662374821\n",
      "[[1575    0]\n",
      " [1221    0]] 0.5633047210300429\n",
      "[[1535    0]\n",
      " [1261    0]] 0.5489985693848355\n",
      "[[1570    0]\n",
      " [1226    0]] 0.5615164520743919\n",
      "[[1663    0]\n",
      " [1133    0]] 0.5947782546494993\n",
      "\n",
      " RANDOM MODEL: \n",
      "\n",
      "[[ 960 1035]\n",
      " [ 410  391]] 0.48319027181688123\n",
      "[[971 921]\n",
      " [444 460]] 0.5118025751072961\n",
      "[[901 831]\n",
      " [546 518]] 0.5075107296137339\n",
      "[[749 826]\n",
      " [623 598]] 0.48175965665236054\n",
      "[[756 779]\n",
      " [634 627]] 0.4946351931330472\n",
      "[[753 817]\n",
      " [615 611]] 0.48783977110157367\n",
      "[[846 817]\n",
      " [553 580]] 0.5100143061516452\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "structure_ids = []\n",
    "for line in open('./structures lists/structures human.txt', 'r'):\n",
    "    line = line.strip('\\n')\n",
    "    structure_ids.append(line)\n",
    "# for line in open('./structures lists/structures ecoli.txt', 'r'):\n",
    "#     line = line.strip('\\n')\n",
    "#     structure_ids.append(line)\n",
    "random.shuffle(structure_ids)\n",
    "print(len(structure_ids))\n",
    "\n",
    "for structure_id in structure_ids:\n",
    "    protein = np.load('../data/voxelized data 7x7x7/' + structure_id + '_protein.npy', mmap_mode='r')\n",
    "    rna = np.load('../data/voxelized data 7x7x7/' + structure_id + '_rna.npy', mmap_mode='r')\n",
    "    X.append(protein[:20])\n",
    "    X.append(protein[-20:])\n",
    "    # rna = list(map(sum, rna))\n",
    "    Y.append(rna[:20])\n",
    "    Y.append(rna[-20:])\n",
    "\n",
    "X = np.concatenate(X)\n",
    "Y = np.concatenate(Y)\n",
    "Y[Y > 0] = 1\n",
    "\n",
    "num_train = int(X.shape[0]*0.7)\n",
    "X_train = X[:num_train]\n",
    "Y_train = Y[:num_train]\n",
    "X_test = X[num_train:]\n",
    "Y_test = Y[num_train:]\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "ins = tf.keras.layers.Input((7, 7, 7, 3))\n",
    "\n",
    "conv1 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same')(ins)\n",
    "batch1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "relu1 = tf.keras.layers.Activation('relu')(batch1)\n",
    "conv2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same')(relu1)\n",
    "batch2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "relu2 = tf.keras.layers.Activation('relu')(batch2)\n",
    "maxp1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(relu2)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp1)\n",
    "batch3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "relu3 = tf.keras.layers.Activation('relu')(batch3)\n",
    "conv4 = tf.keras.layers.Conv3D(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu')(relu3)\n",
    "batch4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "relu4 = tf.keras.layers.Activation('relu')(batch4)\n",
    "maxp2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(relu4)\n",
    "\n",
    "batch = tf.keras.layers.BatchNormalization()(maxp2)\n",
    "flat = tf.keras.layers.Flatten()(batch)\n",
    "dens2 = tf.keras.layers.Dense(units=1024, activation='relu')(flat)\n",
    "drop2 = tf.keras.layers.Dropout(0.6)(dens2)\n",
    "outs = tf.keras.layers.Dense(units=7, activation='sigmoid')(drop2)\n",
    "model = tf.keras.models.Model(inputs=ins, outputs=outs)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, Y_train, validation_split=0.33, epochs=500, batch_size=200, callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "model_best = model\n",
    "model_best.load_weights(\"weights.best.hdf5\")\n",
    "# print(model.evaluate(X_test, Y_test, verbose=0, batch_size=100))\n",
    "Y_pred = model_best.predict(X_test, batch_size=200)\n",
    "\n",
    "#CNN\n",
    "Y_pred[Y_pred >= 0.5] = 1\n",
    "Y_pred[Y_pred < 0.5] = 0\n",
    "\n",
    "confusion_matrix = [sklearn.metrics.confusion_matrix(Y_test[:,i], Y_pred[:,i]) for i in range(7)]\n",
    "accuracy = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix]\n",
    "\n",
    "print('CNN: \\n')\n",
    "for i in range(len(confusion_matrix)):\n",
    "    print(confusion_matrix[i], accuracy[i])\n",
    "\n",
    "# baseline model\n",
    "# predict all zeros; at least 50% correct predictions because there are 1/2 of negative examples\n",
    "# (Yi_true = [0, 0, 0, 0, 0])\n",
    "# Y_pred_base = np.zeros(Y_test.shape)\n",
    "\n",
    "po = np.sum(Y_train, axis=0)/Y_train.shape[0]\n",
    "po[po >= 0.5] = 1\n",
    "po[po < 0.5] = 0\n",
    "\n",
    "Y_pred_base = np.tile(po, (Y_test.shape[0],1))\n",
    "Y_pred_base[Y_pred_base >= 0.5] = 1\n",
    "Y_pred_base[Y_pred_base < 0.5] = 0\n",
    "\n",
    "confusion_matrix_base = [sklearn.metrics.confusion_matrix(Y_test[:,i], Y_pred_base[:,i]) for i in range(7)]\n",
    "accuracy_base = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_base]\n",
    "\n",
    "print(f'\\n BASELINE MODEL: \\n')\n",
    "for i in range(len(confusion_matrix_base)):\n",
    "    print(confusion_matrix_base[i], accuracy_base[i])\n",
    "\n",
    "#random model\n",
    "Y_pred_random = np.random.random(Y_test.shape)\n",
    "Y_pred_random[Y_pred_random >= 0.5] = 1\n",
    "Y_pred_random[Y_pred_random < 0.5] = 0\n",
    "\n",
    "confusion_matrix_random = [sklearn.metrics.confusion_matrix(Y_test[:,i], Y_pred_random[:,i]) for i in range(7)]\n",
    "accuracy_random = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_random]\n",
    "\n",
    "print(f'\\n RANDOM MODEL: \\n')\n",
    "for i in range(len(confusion_matrix_random)):\n",
    "    print(confusion_matrix_random[i], accuracy_random[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
