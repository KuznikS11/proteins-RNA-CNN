{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549\n",
      "24676 13143 37819 94223 334320\n",
      "0.3475237314577329 32744 116184\n",
      "(162070, 17)\n",
      "24673 162070\n",
      "24676 13143 0 0\n",
      "13142 32744 116184\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14, 14, 17, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 14, 14, 17, 64)    5248      \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 17, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 14, 14, 17, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 7, 7, 8, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 7, 8, 32)       27680     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 7, 7, 8, 16)       13840     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 7, 7, 8, 16)       6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 3, 3, 4, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 3, 3, 4, 16)       6928      \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 3, 3, 4, 8)        3464      \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 3, 3, 4, 4)        868       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 2, 4)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 1, 2, 4)        16        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                4369      \n",
      "=================================================================\n",
      "Total params: 154,653\n",
      "Trainable params: 154,645\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "24/24 [==============================] - 52s 2s/step - loss: 0.6911 - acc: 0.5379 - mean_squared_error: 0.2489 - val_loss: 0.6849 - val_acc: 0.5807 - val_mean_squared_error: 0.2459\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.6809 - acc: 0.5694 - mean_squared_error: 0.2439 - val_loss: 0.6830 - val_acc: 0.5267 - val_mean_squared_error: 0.2450\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.6725 - acc: 0.5858 - mean_squared_error: 0.2398 - val_loss: 0.6777 - val_acc: 0.5737 - val_mean_squared_error: 0.2423\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.6627 - acc: 0.6053 - mean_squared_error: 0.2351 - val_loss: 0.6825 - val_acc: 0.5643 - val_mean_squared_error: 0.2447\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.6566 - acc: 0.6133 - mean_squared_error: 0.2322 - val_loss: 0.6560 - val_acc: 0.7346 - val_mean_squared_error: 0.2315\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.6472 - acc: 0.6284 - mean_squared_error: 0.2278 - val_loss: 0.6761 - val_acc: 0.5914 - val_mean_squared_error: 0.2415\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.6388 - acc: 0.6363 - mean_squared_error: 0.2241 - val_loss: 0.6342 - val_acc: 0.8994 - val_mean_squared_error: 0.2207\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.6294 - acc: 0.6461 - mean_squared_error: 0.2198 - val_loss: 0.6577 - val_acc: 0.7336 - val_mean_squared_error: 0.2323\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.6227 - acc: 0.6520 - mean_squared_error: 0.2170 - val_loss: 0.6348 - val_acc: 0.8325 - val_mean_squared_error: 0.2210\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.6154 - acc: 0.6595 - mean_squared_error: 0.2137 - val_loss: 0.6437 - val_acc: 0.8013 - val_mean_squared_error: 0.2253\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.6041 - acc: 0.6724 - mean_squared_error: 0.2087 - val_loss: 0.5918 - val_acc: 0.9003 - val_mean_squared_error: 0.1994\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.5949 - acc: 0.6816 - mean_squared_error: 0.2046 - val_loss: 0.4937 - val_acc: 0.9217 - val_mean_squared_error: 0.1528\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5828 - acc: 0.6911 - mean_squared_error: 0.1996 - val_loss: 0.4889 - val_acc: 0.9352 - val_mean_squared_error: 0.1505\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5649 - acc: 0.7070 - mean_squared_error: 0.1920 - val_loss: 0.4648 - val_acc: 0.9118 - val_mean_squared_error: 0.1397\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5642 - acc: 0.7056 - mean_squared_error: 0.1918 - val_loss: 0.5324 - val_acc: 0.8922 - val_mean_squared_error: 0.1699\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5459 - acc: 0.7218 - mean_squared_error: 0.1840 - val_loss: 0.3712 - val_acc: 0.9316 - val_mean_squared_error: 0.1015\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5261 - acc: 0.7355 - mean_squared_error: 0.1761 - val_loss: 0.4413 - val_acc: 0.9167 - val_mean_squared_error: 0.1316\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5162 - acc: 0.7440 - mean_squared_error: 0.1720 - val_loss: 0.3022 - val_acc: 0.9376 - val_mean_squared_error: 0.0768\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.5081 - acc: 0.7498 - mean_squared_error: 0.1689 - val_loss: 0.2611 - val_acc: 0.9485 - val_mean_squared_error: 0.0633\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.4969 - acc: 0.7580 - mean_squared_error: 0.1646 - val_loss: 0.3351 - val_acc: 0.9280 - val_mean_squared_error: 0.0895\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.4885 - acc: 0.7620 - mean_squared_error: 0.1615 - val_loss: 0.2746 - val_acc: 0.9593 - val_mean_squared_error: 0.0668\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4744 - acc: 0.7715 - mean_squared_error: 0.1560 - val_loss: 0.3295 - val_acc: 0.9331 - val_mean_squared_error: 0.0875\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.4663 - acc: 0.7769 - mean_squared_error: 0.1529 - val_loss: 0.3404 - val_acc: 0.9215 - val_mean_squared_error: 0.0905\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4555 - acc: 0.7836 - mean_squared_error: 0.1489 - val_loss: 0.3669 - val_acc: 0.9065 - val_mean_squared_error: 0.1001\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4498 - acc: 0.7857 - mean_squared_error: 0.1469 - val_loss: 0.2915 - val_acc: 0.9235 - val_mean_squared_error: 0.0750\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4468 - acc: 0.7884 - mean_squared_error: 0.1457 - val_loss: 0.3465 - val_acc: 0.9194 - val_mean_squared_error: 0.0935\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4326 - acc: 0.7975 - mean_squared_error: 0.1404 - val_loss: 0.3206 - val_acc: 0.9225 - val_mean_squared_error: 0.0842\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4270 - acc: 0.7992 - mean_squared_error: 0.1386 - val_loss: 0.3040 - val_acc: 0.9219 - val_mean_squared_error: 0.0788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.4159 - acc: 0.8070 - mean_squared_error: 0.1344 - val_loss: 0.3726 - val_acc: 0.8944 - val_mean_squared_error: 0.1044\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.4117 - acc: 0.8102 - mean_squared_error: 0.1323 - val_loss: 0.3200 - val_acc: 0.9322 - val_mean_squared_error: 0.0828\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3964 - acc: 0.8184 - mean_squared_error: 0.1272 - val_loss: 0.4432 - val_acc: 0.8876 - val_mean_squared_error: 0.1252\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.4053 - acc: 0.8125 - mean_squared_error: 0.1305 - val_loss: 0.3765 - val_acc: 0.8951 - val_mean_squared_error: 0.1039\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3890 - acc: 0.8223 - mean_squared_error: 0.1245 - val_loss: 0.3959 - val_acc: 0.8857 - val_mean_squared_error: 0.1123\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3810 - acc: 0.8262 - mean_squared_error: 0.1216 - val_loss: 0.2896 - val_acc: 0.9350 - val_mean_squared_error: 0.0734\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3762 - acc: 0.8303 - mean_squared_error: 0.1197 - val_loss: 0.4252 - val_acc: 0.8857 - val_mean_squared_error: 0.1199\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3812 - acc: 0.8262 - mean_squared_error: 0.1217 - val_loss: 0.4450 - val_acc: 0.8321 - val_mean_squared_error: 0.1292\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.3633 - acc: 0.8359 - mean_squared_error: 0.1155 - val_loss: 0.3255 - val_acc: 0.9172 - val_mean_squared_error: 0.0861\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3596 - acc: 0.8389 - mean_squared_error: 0.1140 - val_loss: 0.3651 - val_acc: 0.8965 - val_mean_squared_error: 0.1011\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3480 - acc: 0.8443 - mean_squared_error: 0.1100 - val_loss: 0.3757 - val_acc: 0.8859 - val_mean_squared_error: 0.1040\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3492 - acc: 0.8437 - mean_squared_error: 0.1104 - val_loss: 0.4461 - val_acc: 0.8496 - val_mean_squared_error: 0.1316\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3471 - acc: 0.8454 - mean_squared_error: 0.1096 - val_loss: 0.5332 - val_acc: 0.7951 - val_mean_squared_error: 0.1612\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3424 - acc: 0.8480 - mean_squared_error: 0.1080 - val_loss: 0.5151 - val_acc: 0.7793 - val_mean_squared_error: 0.1624\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3255 - acc: 0.8567 - mean_squared_error: 0.1019 - val_loss: 0.3564 - val_acc: 0.8999 - val_mean_squared_error: 0.0958\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3264 - acc: 0.8553 - mean_squared_error: 0.1026 - val_loss: 0.2461 - val_acc: 0.9356 - val_mean_squared_error: 0.0633\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3279 - acc: 0.8534 - mean_squared_error: 0.1034 - val_loss: 0.2817 - val_acc: 0.9272 - val_mean_squared_error: 0.0729\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3253 - acc: 0.8568 - mean_squared_error: 0.1020 - val_loss: 0.2244 - val_acc: 0.9445 - val_mean_squared_error: 0.0538\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3211 - acc: 0.8577 - mean_squared_error: 0.1009 - val_loss: 0.3285 - val_acc: 0.9075 - val_mean_squared_error: 0.0868\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3151 - acc: 0.8616 - mean_squared_error: 0.0986 - val_loss: 0.4532 - val_acc: 0.8602 - val_mean_squared_error: 0.1220\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3208 - acc: 0.8589 - mean_squared_error: 0.1004 - val_loss: 0.4691 - val_acc: 0.8603 - val_mean_squared_error: 0.1251\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3072 - acc: 0.8653 - mean_squared_error: 0.0961 - val_loss: 0.3071 - val_acc: 0.9173 - val_mean_squared_error: 0.0769\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3094 - acc: 0.8640 - mean_squared_error: 0.0969 - val_loss: 0.2939 - val_acc: 0.9207 - val_mean_squared_error: 0.0723\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.3041 - acc: 0.8674 - mean_squared_error: 0.0948 - val_loss: 0.2798 - val_acc: 0.9216 - val_mean_squared_error: 0.0704\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2961 - acc: 0.8708 - mean_squared_error: 0.0922 - val_loss: 0.3072 - val_acc: 0.9147 - val_mean_squared_error: 0.0771\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2888 - acc: 0.8748 - mean_squared_error: 0.0897 - val_loss: 0.3110 - val_acc: 0.9142 - val_mean_squared_error: 0.0788\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2944 - acc: 0.8724 - mean_squared_error: 0.0915 - val_loss: 0.2821 - val_acc: 0.9252 - val_mean_squared_error: 0.0705\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.3053 - acc: 0.8663 - mean_squared_error: 0.0953 - val_loss: 0.4302 - val_acc: 0.8677 - val_mean_squared_error: 0.1148\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2853 - acc: 0.8765 - mean_squared_error: 0.0885 - val_loss: 0.2577 - val_acc: 0.9278 - val_mean_squared_error: 0.0638\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2835 - acc: 0.8778 - mean_squared_error: 0.0879 - val_loss: 0.4034 - val_acc: 0.8801 - val_mean_squared_error: 0.1057\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2805 - acc: 0.8789 - mean_squared_error: 0.0869 - val_loss: 0.5236 - val_acc: 0.8105 - val_mean_squared_error: 0.1458\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2781 - acc: 0.8799 - mean_squared_error: 0.0861 - val_loss: 0.2598 - val_acc: 0.9272 - val_mean_squared_error: 0.0645\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2772 - acc: 0.8803 - mean_squared_error: 0.0859 - val_loss: 0.3639 - val_acc: 0.8911 - val_mean_squared_error: 0.0941\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2720 - acc: 0.8830 - mean_squared_error: 0.0841 - val_loss: 0.2155 - val_acc: 0.9384 - val_mean_squared_error: 0.0530\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2824 - acc: 0.8778 - mean_squared_error: 0.0876 - val_loss: 0.3984 - val_acc: 0.8626 - val_mean_squared_error: 0.1119\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2619 - acc: 0.8887 - mean_squared_error: 0.0805 - val_loss: 0.3021 - val_acc: 0.9109 - val_mean_squared_error: 0.0769\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2627 - acc: 0.8885 - mean_squared_error: 0.0807 - val_loss: 0.3489 - val_acc: 0.8899 - val_mean_squared_error: 0.0932\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2672 - acc: 0.8858 - mean_squared_error: 0.0823 - val_loss: 0.4765 - val_acc: 0.8085 - val_mean_squared_error: 0.1398\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2654 - acc: 0.8868 - mean_squared_error: 0.0817 - val_loss: 0.4123 - val_acc: 0.8458 - val_mean_squared_error: 0.1180\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2466 - acc: 0.8959 - mean_squared_error: 0.0754 - val_loss: 0.2610 - val_acc: 0.9211 - val_mean_squared_error: 0.0663\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2564 - acc: 0.8903 - mean_squared_error: 0.0788 - val_loss: 0.2273 - val_acc: 0.9299 - val_mean_squared_error: 0.0591\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2611 - acc: 0.8889 - mean_squared_error: 0.0803 - val_loss: 0.2299 - val_acc: 0.9289 - val_mean_squared_error: 0.0592\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 47s 2s/step - loss: 0.2543 - acc: 0.8915 - mean_squared_error: 0.0781 - val_loss: 0.2584 - val_acc: 0.9225 - val_mean_squared_error: 0.0653\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2456 - acc: 0.8961 - mean_squared_error: 0.0751 - val_loss: 0.3720 - val_acc: 0.8848 - val_mean_squared_error: 0.0960\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2476 - acc: 0.8953 - mean_squared_error: 0.0758 - val_loss: 0.3718 - val_acc: 0.8877 - val_mean_squared_error: 0.0943\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2538 - acc: 0.8922 - mean_squared_error: 0.0779 - val_loss: 0.3652 - val_acc: 0.8925 - val_mean_squared_error: 0.0909\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2535 - acc: 0.8933 - mean_squared_error: 0.0775 - val_loss: 0.2746 - val_acc: 0.9212 - val_mean_squared_error: 0.0673\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.2455 - acc: 0.8961 - mean_squared_error: 0.0752 - val_loss: 0.2730 - val_acc: 0.9169 - val_mean_squared_error: 0.0688\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2398 - acc: 0.8989 - mean_squared_error: 0.0733 - val_loss: 0.2671 - val_acc: 0.9230 - val_mean_squared_error: 0.0643\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2420 - acc: 0.8979 - mean_squared_error: 0.0740 - val_loss: 0.3200 - val_acc: 0.9018 - val_mean_squared_error: 0.0806\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2430 - acc: 0.8979 - mean_squared_error: 0.0742 - val_loss: 0.3122 - val_acc: 0.9057 - val_mean_squared_error: 0.0784\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.2471 - acc: 0.8956 - mean_squared_error: 0.0755 - val_loss: 0.3717 - val_acc: 0.8721 - val_mean_squared_error: 0.1007\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2285 - acc: 0.9046 - mean_squared_error: 0.0695 - val_loss: 0.2868 - val_acc: 0.9123 - val_mean_squared_error: 0.0733\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2331 - acc: 0.9026 - mean_squared_error: 0.0709 - val_loss: 0.2860 - val_acc: 0.9130 - val_mean_squared_error: 0.0721\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2369 - acc: 0.9000 - mean_squared_error: 0.0725 - val_loss: 0.3415 - val_acc: 0.8955 - val_mean_squared_error: 0.0864\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2280 - acc: 0.9044 - mean_squared_error: 0.0694 - val_loss: 0.3622 - val_acc: 0.8760 - val_mean_squared_error: 0.0978\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2279 - acc: 0.9045 - mean_squared_error: 0.0694 - val_loss: 0.2996 - val_acc: 0.9091 - val_mean_squared_error: 0.0756\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2217 - acc: 0.9074 - mean_squared_error: 0.0673 - val_loss: 0.3271 - val_acc: 0.8975 - val_mean_squared_error: 0.0825\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2325 - acc: 0.9017 - mean_squared_error: 0.0711 - val_loss: 0.3018 - val_acc: 0.9064 - val_mean_squared_error: 0.0760\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2271 - acc: 0.9059 - mean_squared_error: 0.0689 - val_loss: 0.3035 - val_acc: 0.8950 - val_mean_squared_error: 0.0816\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2096 - acc: 0.9132 - mean_squared_error: 0.0634 - val_loss: 0.2806 - val_acc: 0.9135 - val_mean_squared_error: 0.0709\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2206 - acc: 0.9071 - mean_squared_error: 0.0673 - val_loss: 0.3758 - val_acc: 0.8744 - val_mean_squared_error: 0.0986\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2197 - acc: 0.9088 - mean_squared_error: 0.0667 - val_loss: 0.4876 - val_acc: 0.8392 - val_mean_squared_error: 0.1257\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2205 - acc: 0.9073 - mean_squared_error: 0.0671 - val_loss: 0.3446 - val_acc: 0.8710 - val_mean_squared_error: 0.0980\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2195 - acc: 0.9084 - mean_squared_error: 0.0666 - val_loss: 0.2124 - val_acc: 0.9333 - val_mean_squared_error: 0.0536\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2173 - acc: 0.9085 - mean_squared_error: 0.0661 - val_loss: 0.1975 - val_acc: 0.9383 - val_mean_squared_error: 0.0497\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.2132 - acc: 0.9109 - mean_squared_error: 0.0647 - val_loss: 0.2820 - val_acc: 0.9135 - val_mean_squared_error: 0.0712\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2226 - acc: 0.9074 - mean_squared_error: 0.0675 - val_loss: 0.4816 - val_acc: 0.8308 - val_mean_squared_error: 0.1283\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2181 - acc: 0.9089 - mean_squared_error: 0.0662 - val_loss: 0.3775 - val_acc: 0.8759 - val_mean_squared_error: 0.0972\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2061 - acc: 0.9148 - mean_squared_error: 0.0622 - val_loss: 0.3359 - val_acc: 0.8984 - val_mean_squared_error: 0.0817\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 46s 2s/step - loss: 0.2106 - acc: 0.9124 - mean_squared_error: 0.0639 - val_loss: 0.3250 - val_acc: 0.9059 - val_mean_squared_error: 0.0761\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2144 - acc: 0.9111 - mean_squared_error: 0.0650 - val_loss: 0.2998 - val_acc: 0.9080 - val_mean_squared_error: 0.0735\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.2111 - acc: 0.9125 - mean_squared_error: 0.0639 - val_loss: 0.3255 - val_acc: 0.8965 - val_mean_squared_error: 0.0814\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2114 - acc: 0.9126 - mean_squared_error: 0.0640 - val_loss: 0.2881 - val_acc: 0.9135 - val_mean_squared_error: 0.0697\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2128 - acc: 0.9109 - mean_squared_error: 0.0647 - val_loss: 0.3541 - val_acc: 0.8920 - val_mean_squared_error: 0.0864\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2084 - acc: 0.9137 - mean_squared_error: 0.0630 - val_loss: 0.3809 - val_acc: 0.8728 - val_mean_squared_error: 0.0990\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 46s 2s/step - loss: 0.1962 - acc: 0.9189 - mean_squared_error: 0.0592 - val_loss: 0.2962 - val_acc: 0.9030 - val_mean_squared_error: 0.0772\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2063 - acc: 0.9142 - mean_squared_error: 0.0625 - val_loss: 0.3649 - val_acc: 0.8761 - val_mean_squared_error: 0.0962\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.2017 - acc: 0.9167 - mean_squared_error: 0.0610 - val_loss: 0.3732 - val_acc: 0.8788 - val_mean_squared_error: 0.0950\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1973 - acc: 0.9187 - mean_squared_error: 0.0596 - val_loss: 0.3933 - val_acc: 0.8681 - val_mean_squared_error: 0.1019\n",
      "Epoch 109/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1946 - acc: 0.9194 - mean_squared_error: 0.0588 - val_loss: 0.4615 - val_acc: 0.8324 - val_mean_squared_error: 0.1258\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1944 - acc: 0.9198 - mean_squared_error: 0.0587 - val_loss: 0.3178 - val_acc: 0.8992 - val_mean_squared_error: 0.0799\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2027 - acc: 0.9151 - mean_squared_error: 0.0615 - val_loss: 0.3056 - val_acc: 0.9064 - val_mean_squared_error: 0.0750\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.2051 - acc: 0.9146 - mean_squared_error: 0.0622 - val_loss: 0.2889 - val_acc: 0.9084 - val_mean_squared_error: 0.0729\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 48s 2s/step - loss: 0.2077 - acc: 0.9131 - mean_squared_error: 0.0631 - val_loss: 0.5320 - val_acc: 0.8046 - val_mean_squared_error: 0.1439\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1958 - acc: 0.9191 - mean_squared_error: 0.0591 - val_loss: 0.3730 - val_acc: 0.8810 - val_mean_squared_error: 0.0938\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1906 - acc: 0.9207 - mean_squared_error: 0.0577 - val_loss: 0.3804 - val_acc: 0.8690 - val_mean_squared_error: 0.1001\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1850 - acc: 0.9237 - mean_squared_error: 0.0557 - val_loss: 0.3675 - val_acc: 0.8720 - val_mean_squared_error: 0.0982\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1943 - acc: 0.9199 - mean_squared_error: 0.0586 - val_loss: 0.5428 - val_acc: 0.7542 - val_mean_squared_error: 0.1683\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1969 - acc: 0.9182 - mean_squared_error: 0.0595 - val_loss: 0.2464 - val_acc: 0.9210 - val_mean_squared_error: 0.0628\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1894 - acc: 0.9219 - mean_squared_error: 0.0571 - val_loss: 0.2566 - val_acc: 0.9174 - val_mean_squared_error: 0.0658\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1857 - acc: 0.9231 - mean_squared_error: 0.0560 - val_loss: 0.2810 - val_acc: 0.9106 - val_mean_squared_error: 0.0711\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1855 - acc: 0.9230 - mean_squared_error: 0.0560 - val_loss: 0.3130 - val_acc: 0.9010 - val_mean_squared_error: 0.0784\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1988 - acc: 0.9174 - mean_squared_error: 0.0601 - val_loss: 0.3401 - val_acc: 0.8969 - val_mean_squared_error: 0.0823\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1910 - acc: 0.9205 - mean_squared_error: 0.0577 - val_loss: 0.4265 - val_acc: 0.8682 - val_mean_squared_error: 0.1035\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1844 - acc: 0.9238 - mean_squared_error: 0.0556 - val_loss: 0.3683 - val_acc: 0.8872 - val_mean_squared_error: 0.0892\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1809 - acc: 0.9257 - mean_squared_error: 0.0545 - val_loss: 0.3464 - val_acc: 0.8893 - val_mean_squared_error: 0.0861\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 46s 2s/step - loss: 0.1888 - acc: 0.9213 - mean_squared_error: 0.0572 - val_loss: 0.3493 - val_acc: 0.8967 - val_mean_squared_error: 0.0821\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1830 - acc: 0.9241 - mean_squared_error: 0.0552 - val_loss: 0.2611 - val_acc: 0.9225 - val_mean_squared_error: 0.0622\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1881 - acc: 0.9225 - mean_squared_error: 0.0567 - val_loss: 0.4003 - val_acc: 0.8736 - val_mean_squared_error: 0.0987\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1838 - acc: 0.9238 - mean_squared_error: 0.0554 - val_loss: 0.3395 - val_acc: 0.8877 - val_mean_squared_error: 0.0873\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1847 - acc: 0.9237 - mean_squared_error: 0.0557 - val_loss: 0.3152 - val_acc: 0.8969 - val_mean_squared_error: 0.0804\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1846 - acc: 0.9235 - mean_squared_error: 0.0557 - val_loss: 0.3941 - val_acc: 0.8714 - val_mean_squared_error: 0.0999\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1811 - acc: 0.9251 - mean_squared_error: 0.0546 - val_loss: 0.4196 - val_acc: 0.8594 - val_mean_squared_error: 0.1080\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1781 - acc: 0.9269 - mean_squared_error: 0.0535 - val_loss: 0.4182 - val_acc: 0.8627 - val_mean_squared_error: 0.1056\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1795 - acc: 0.9261 - mean_squared_error: 0.0540 - val_loss: 0.3284 - val_acc: 0.8990 - val_mean_squared_error: 0.0800\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1811 - acc: 0.9252 - mean_squared_error: 0.0548 - val_loss: 0.3435 - val_acc: 0.8805 - val_mean_squared_error: 0.0911\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1768 - acc: 0.9275 - mean_squared_error: 0.0532 - val_loss: 0.3197 - val_acc: 0.8972 - val_mean_squared_error: 0.0803\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1824 - acc: 0.9237 - mean_squared_error: 0.0554 - val_loss: 0.2920 - val_acc: 0.9092 - val_mean_squared_error: 0.0721\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1753 - acc: 0.9273 - mean_squared_error: 0.0529 - val_loss: 0.4606 - val_acc: 0.8297 - val_mean_squared_error: 0.1251\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1837 - acc: 0.9241 - mean_squared_error: 0.0554 - val_loss: 0.3601 - val_acc: 0.8837 - val_mean_squared_error: 0.0908\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1779 - acc: 0.9261 - mean_squared_error: 0.0538 - val_loss: 0.4245 - val_acc: 0.8548 - val_mean_squared_error: 0.1107\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1674 - acc: 0.9313 - mean_squared_error: 0.0503 - val_loss: 0.3918 - val_acc: 0.8694 - val_mean_squared_error: 0.1000\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1691 - acc: 0.9304 - mean_squared_error: 0.0508 - val_loss: 0.5353 - val_acc: 0.7746 - val_mean_squared_error: 0.1585\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1665 - acc: 0.9319 - mean_squared_error: 0.0500 - val_loss: 0.2526 - val_acc: 0.9210 - val_mean_squared_error: 0.0627\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1759 - acc: 0.9273 - mean_squared_error: 0.0531 - val_loss: 0.2712 - val_acc: 0.9180 - val_mean_squared_error: 0.0653\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1806 - acc: 0.9253 - mean_squared_error: 0.0543 - val_loss: 0.3301 - val_acc: 0.8962 - val_mean_squared_error: 0.0817\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1738 - acc: 0.9279 - mean_squared_error: 0.0525 - val_loss: 0.3859 - val_acc: 0.8805 - val_mean_squared_error: 0.0940\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1673 - acc: 0.9312 - mean_squared_error: 0.0503 - val_loss: 0.3815 - val_acc: 0.8845 - val_mean_squared_error: 0.0914\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1688 - acc: 0.9306 - mean_squared_error: 0.0507 - val_loss: 0.3365 - val_acc: 0.8945 - val_mean_squared_error: 0.0826\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 46s 2s/step - loss: 0.1710 - acc: 0.9295 - mean_squared_error: 0.0515 - val_loss: 0.3557 - val_acc: 0.8937 - val_mean_squared_error: 0.0847\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1663 - acc: 0.9319 - mean_squared_error: 0.0499 - val_loss: 0.3124 - val_acc: 0.9043 - val_mean_squared_error: 0.0750\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1709 - acc: 0.9291 - mean_squared_error: 0.0516 - val_loss: 0.3878 - val_acc: 0.8862 - val_mean_squared_error: 0.0901\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1748 - acc: 0.9277 - mean_squared_error: 0.0526 - val_loss: 0.3439 - val_acc: 0.9019 - val_mean_squared_error: 0.0788\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1788 - acc: 0.9255 - mean_squared_error: 0.0541 - val_loss: 0.3625 - val_acc: 0.8889 - val_mean_squared_error: 0.0873\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1638 - acc: 0.9328 - mean_squared_error: 0.0492 - val_loss: 0.3074 - val_acc: 0.9060 - val_mean_squared_error: 0.0743\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 48s 2s/step - loss: 0.1626 - acc: 0.9326 - mean_squared_error: 0.0489 - val_loss: 0.3805 - val_acc: 0.8783 - val_mean_squared_error: 0.0947\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1683 - acc: 0.9312 - mean_squared_error: 0.0506 - val_loss: 0.3498 - val_acc: 0.8917 - val_mean_squared_error: 0.0852\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1643 - acc: 0.9321 - mean_squared_error: 0.0495 - val_loss: 0.3457 - val_acc: 0.8868 - val_mean_squared_error: 0.0875\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1612 - acc: 0.9336 - mean_squared_error: 0.0485 - val_loss: 0.3163 - val_acc: 0.8970 - val_mean_squared_error: 0.0800\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1696 - acc: 0.9299 - mean_squared_error: 0.0511 - val_loss: 0.4530 - val_acc: 0.8450 - val_mean_squared_error: 0.1173\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1635 - acc: 0.9326 - mean_squared_error: 0.0492 - val_loss: 0.4186 - val_acc: 0.8724 - val_mean_squared_error: 0.1003\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1690 - acc: 0.9302 - mean_squared_error: 0.0509 - val_loss: 0.3318 - val_acc: 0.8906 - val_mean_squared_error: 0.0841\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1683 - acc: 0.9304 - mean_squared_error: 0.0507 - val_loss: 0.3524 - val_acc: 0.8911 - val_mean_squared_error: 0.0853\n",
      "Epoch 163/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1574 - acc: 0.9356 - mean_squared_error: 0.0472 - val_loss: 0.5737 - val_acc: 0.7966 - val_mean_squared_error: 0.1526\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1619 - acc: 0.9333 - mean_squared_error: 0.0487 - val_loss: 0.4012 - val_acc: 0.8688 - val_mean_squared_error: 0.1007\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1559 - acc: 0.9354 - mean_squared_error: 0.0470 - val_loss: 0.4055 - val_acc: 0.8739 - val_mean_squared_error: 0.0979\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1627 - acc: 0.9328 - mean_squared_error: 0.0490 - val_loss: 0.3113 - val_acc: 0.9080 - val_mean_squared_error: 0.0731\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1599 - acc: 0.9344 - mean_squared_error: 0.0480 - val_loss: 0.3976 - val_acc: 0.8677 - val_mean_squared_error: 0.1010\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1552 - acc: 0.9360 - mean_squared_error: 0.0467 - val_loss: 0.3036 - val_acc: 0.9053 - val_mean_squared_error: 0.0745\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1541 - acc: 0.9366 - mean_squared_error: 0.0463 - val_loss: 0.2554 - val_acc: 0.9216 - val_mean_squared_error: 0.0622\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1534 - acc: 0.9365 - mean_squared_error: 0.0461 - val_loss: 0.3221 - val_acc: 0.9022 - val_mean_squared_error: 0.0774\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1606 - acc: 0.9338 - mean_squared_error: 0.0483 - val_loss: 0.4053 - val_acc: 0.8772 - val_mean_squared_error: 0.0965\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1602 - acc: 0.9337 - mean_squared_error: 0.0483 - val_loss: 0.4017 - val_acc: 0.8780 - val_mean_squared_error: 0.0959\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1702 - acc: 0.9294 - mean_squared_error: 0.0513 - val_loss: 0.4389 - val_acc: 0.8723 - val_mean_squared_error: 0.1012\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1568 - acc: 0.9360 - mean_squared_error: 0.0469 - val_loss: 0.2964 - val_acc: 0.9197 - val_mean_squared_error: 0.0654\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1537 - acc: 0.9368 - mean_squared_error: 0.0462 - val_loss: 0.3754 - val_acc: 0.8833 - val_mean_squared_error: 0.0910\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1542 - acc: 0.9363 - mean_squared_error: 0.0463 - val_loss: 0.3767 - val_acc: 0.8861 - val_mean_squared_error: 0.0893\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1526 - acc: 0.9373 - mean_squared_error: 0.0459 - val_loss: 0.3495 - val_acc: 0.8955 - val_mean_squared_error: 0.0824\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1526 - acc: 0.9373 - mean_squared_error: 0.0458 - val_loss: 0.3237 - val_acc: 0.8980 - val_mean_squared_error: 0.0798\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1646 - acc: 0.9321 - mean_squared_error: 0.0496 - val_loss: 0.4076 - val_acc: 0.8667 - val_mean_squared_error: 0.1025\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1525 - acc: 0.9374 - mean_squared_error: 0.0458 - val_loss: 0.3254 - val_acc: 0.8963 - val_mean_squared_error: 0.0805\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1472 - acc: 0.9398 - mean_squared_error: 0.0441 - val_loss: 0.4068 - val_acc: 0.8695 - val_mean_squared_error: 0.1008\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1510 - acc: 0.9381 - mean_squared_error: 0.0454 - val_loss: 0.3540 - val_acc: 0.8915 - val_mean_squared_error: 0.0853\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1537 - acc: 0.9366 - mean_squared_error: 0.0462 - val_loss: 0.3738 - val_acc: 0.8825 - val_mean_squared_error: 0.0909\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1507 - acc: 0.9377 - mean_squared_error: 0.0453 - val_loss: 0.3925 - val_acc: 0.8773 - val_mean_squared_error: 0.0953\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1506 - acc: 0.9382 - mean_squared_error: 0.0452 - val_loss: 0.4311 - val_acc: 0.8682 - val_mean_squared_error: 0.1031\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1547 - acc: 0.9367 - mean_squared_error: 0.0464 - val_loss: 0.3737 - val_acc: 0.8945 - val_mean_squared_error: 0.0844\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1453 - acc: 0.9400 - mean_squared_error: 0.0437 - val_loss: 0.3794 - val_acc: 0.8816 - val_mean_squared_error: 0.0919\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1430 - acc: 0.9418 - mean_squared_error: 0.0428 - val_loss: 0.4376 - val_acc: 0.8645 - val_mean_squared_error: 0.1055\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1483 - acc: 0.9386 - mean_squared_error: 0.0446 - val_loss: 0.4690 - val_acc: 0.8604 - val_mean_squared_error: 0.1097\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1592 - acc: 0.9344 - mean_squared_error: 0.0479 - val_loss: 0.4263 - val_acc: 0.8665 - val_mean_squared_error: 0.1038\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.1443 - acc: 0.9405 - mean_squared_error: 0.0434 - val_loss: 0.3986 - val_acc: 0.8704 - val_mean_squared_error: 0.0993\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.1502 - acc: 0.9385 - mean_squared_error: 0.0451 - val_loss: 0.3805 - val_acc: 0.8736 - val_mean_squared_error: 0.0969\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1416 - acc: 0.9414 - mean_squared_error: 0.0425 - val_loss: 0.3059 - val_acc: 0.9068 - val_mean_squared_error: 0.0736\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1432 - acc: 0.9412 - mean_squared_error: 0.0430 - val_loss: 0.3688 - val_acc: 0.8908 - val_mean_squared_error: 0.0864\n",
      "(161792, 17)\n",
      "(162070, 17)\n",
      "CNN: \n",
      "\n",
      "level 1\n",
      "[[142832  13472]\n",
      " [  3062   2426]] 0.9 0.68\n",
      "level 2\n",
      "[[142593  14198]\n",
      " [  2633   2368]] 0.9 0.69\n",
      "level 3\n",
      "[[144236  12669]\n",
      " [  2587   2300]] 0.91 0.69\n",
      "level 4\n",
      "[[145128  11717]\n",
      " [  2571   2376]] 0.91 0.7\n",
      "level 5\n",
      "[[145665  10949]\n",
      " [  2549   2629]] 0.92 0.72\n",
      "level 6\n",
      "[[144886  11249]\n",
      " [  2460   3197]] 0.92 0.75\n",
      "level 7\n",
      "[[143490  11996]\n",
      " [  2443   3863]] 0.91 0.77\n",
      "level 8\n",
      "[[142264  12829]\n",
      " [  2208   4491]] 0.91 0.79\n",
      "level 9\n",
      "[[140396  14241]\n",
      " [  1977   5178]] 0.9 0.82\n",
      "level 10\n",
      "[[138929  15588]\n",
      " [  1862   5413]] 0.89 0.82\n",
      "level 11\n",
      "[[138099  16486]\n",
      " [  1794   5413]] 0.89 0.82\n",
      "level 12\n",
      "[[137181  17553]\n",
      " [  1798   5260]] 0.88 0.82\n",
      "level 13\n",
      "[[136168  18798]\n",
      " [  1947   4879]] 0.87 0.8\n",
      "level 14\n",
      "[[134332  20935]\n",
      " [  2237   4288]] 0.86 0.76\n",
      "level 15\n",
      "[[135738  19805]\n",
      " [  2420   3829]] 0.86 0.74\n",
      "level 16\n",
      "[[135490  20402]\n",
      " [  2708   3192]] 0.86 0.71\n",
      "level 17\n",
      "[[140100  16178]\n",
      " [  3100   2414]] 0.88 0.67\n",
      "(161792, 17)\n",
      "\n",
      " BASELINE MODEL: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1\n",
      "[[156304      0]\n",
      " [  5488      0]] 0.97 0.5\n",
      "level 2\n",
      "[[156791      0]\n",
      " [  5001      0]] 0.97 0.5\n",
      "level 3\n",
      "[[156905      0]\n",
      " [  4887      0]] 0.97 0.5\n",
      "level 4\n",
      "[[156845      0]\n",
      " [  4947      0]] 0.97 0.5\n",
      "level 5\n",
      "[[156614      0]\n",
      " [  5178      0]] 0.97 0.5\n",
      "level 6\n",
      "[[156135      0]\n",
      " [  5657      0]] 0.97 0.5\n",
      "level 7\n",
      "[[155486      0]\n",
      " [  6306      0]] 0.96 0.5\n",
      "level 8\n",
      "[[155093      0]\n",
      " [  6699      0]] 0.96 0.5\n",
      "level 9\n",
      "[[154637      0]\n",
      " [  7155      0]] 0.96 0.5\n",
      "level 10\n",
      "[[154517      0]\n",
      " [  7275      0]] 0.96 0.5\n",
      "level 11\n",
      "[[154585      0]\n",
      " [  7207      0]] 0.96 0.5\n",
      "level 12\n",
      "[[154734      0]\n",
      " [  7058      0]] 0.96 0.5\n",
      "level 13\n",
      "[[154966      0]\n",
      " [  6826      0]] 0.96 0.5\n",
      "level 14\n",
      "[[155267      0]\n",
      " [  6525      0]] 0.96 0.5\n",
      "level 15\n",
      "[[155543      0]\n",
      " [  6249      0]] 0.96 0.5\n",
      "level 16\n",
      "[[155892      0]\n",
      " [  5900      0]] 0.96 0.5\n",
      "level 17\n",
      "[[156278      0]\n",
      " [  5514      0]] 0.97 0.5\n",
      "\n",
      " RANDOM MODEL: \n",
      "\n",
      "level 1\n",
      "[[78204 78100]\n",
      " [ 2773  2715]] 0.5 0.5\n",
      "level 2\n",
      "[[78562 78229]\n",
      " [ 2472  2529]] 0.5 0.5\n",
      "level 3\n",
      "[[78502 78403]\n",
      " [ 2365  2522]] 0.5 0.51\n",
      "level 4\n",
      "[[78318 78527]\n",
      " [ 2493  2454]] 0.5 0.5\n",
      "level 5\n",
      "[[78001 78613]\n",
      " [ 2539  2639]] 0.5 0.5\n",
      "level 6\n",
      "[[77928 78207]\n",
      " [ 2797  2860]] 0.5 0.5\n",
      "level 7\n",
      "[[77559 77927]\n",
      " [ 3178  3128]] 0.5 0.5\n",
      "level 8\n",
      "[[77353 77740]\n",
      " [ 3314  3385]] 0.5 0.5\n",
      "level 9\n",
      "[[77171 77466]\n",
      " [ 3626  3529]] 0.5 0.5\n",
      "level 10\n",
      "[[77745 76772]\n",
      " [ 3644  3631]] 0.5 0.5\n",
      "level 11\n",
      "[[76891 77694]\n",
      " [ 3577  3630]] 0.5 0.5\n",
      "level 12\n",
      "[[77449 77285]\n",
      " [ 3459  3599]] 0.5 0.51\n",
      "level 13\n",
      "[[77572 77394]\n",
      " [ 3390  3436]] 0.5 0.5\n",
      "level 14\n",
      "[[77874 77393]\n",
      " [ 3279  3246]] 0.5 0.5\n",
      "level 15\n",
      "[[77701 77842]\n",
      " [ 3153  3096]] 0.5 0.5\n",
      "level 16\n",
      "[[77558 78334]\n",
      " [ 2927  2973]] 0.5 0.5\n",
      "level 17\n",
      "[[78103 78175]\n",
      " [ 2759  2755]] 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "\n",
    "def generator(X, Y, batch_size=32, train=True):\n",
    "    while True:\n",
    "        for offset in range(0, len(X), batch_size):\n",
    "            X_batch = np.stack(X[offset:offset+batch_size], axis=0)\n",
    "            Y_batch = np.stack(Y[offset:offset+batch_size], axis=0)\n",
    "            \n",
    "            if train:\n",
    "                Y_f = np.array(list(map(lambda x:np.sum(np.sum(x, axis=0), axis=0), Y_batch)))\n",
    "                Y_f[Y_f < 25] = 0\n",
    "                Y_f[Y_f >= 25] = 1\n",
    "                \n",
    "            \n",
    "                yield (X_batch, Y_f)\n",
    "            else:\n",
    "                yield X_batch\n",
    "\n",
    "structure_ids = []   \n",
    "for line in open('./structures lists/stucture ids homo sapiens.txt', 'r'):\n",
    "    line = line.strip('\\n').lower()\n",
    "    structure_ids.append(line)\n",
    "for line in open('./structures lists/stucture ids synthetic construct.txt', 'r'):\n",
    "    line = line.strip('\\n').lower()\n",
    "    structure_ids.append(line)\n",
    "for line in open('./structures lists/stucture ids virus.txt', 'r'):\n",
    "    line = line.strip('\\n').lower()\n",
    "    structure_ids.append(line)\n",
    "\n",
    "structure_ids.remove('1a9n')\n",
    "structure_ids.remove('2adc')\n",
    "random.shuffle(structure_ids)\n",
    "print(len(structure_ids))\n",
    "\n",
    "num_test = int(len(structure_ids)*0.3)\n",
    "pp_train = 0\n",
    "pp_test = 0\n",
    "pos = 0\n",
    "neg = 0\n",
    "for i, structure_id in enumerate(structure_ids):\n",
    "    rna = np.load('../data/voxelized data 14x14x17 2/' + structure_id + '_rna_3D.npy', mmap_mode='r')\n",
    "\n",
    "    pp = 0\n",
    "    p = 0\n",
    "    n = 0\n",
    "    for bb in rna:\n",
    "        n_nucleotides = np.sum(bb)\n",
    "        if n_nucleotides >= 100:\n",
    "            pp +=1\n",
    "        if 100 > n_nucleotides > 0:\n",
    "            p +=1\n",
    "        if n_nucleotides == 0:\n",
    "            n +=1\n",
    "    pos +=p\n",
    "    neg +=n\n",
    "    if i <= num_test:\n",
    "        pp_test +=pp\n",
    "    else:\n",
    "        pp_train +=pp\n",
    "\n",
    "proc_test = pp_test/(pp_test+pp_train)\n",
    "pos_test = int(pos*proc_test)\n",
    "neg_test = int(neg*proc_test)\n",
    "\n",
    "print(pp_train, pp_test, (pp_train + pp_test), pos, neg)\n",
    "print(proc_test, pos_test, neg_test)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "num_aa_train = 0\n",
    "num_aa_test = 0\n",
    "num_pp = 0\n",
    "num_p = 0\n",
    "num_n = 0\n",
    "for j, structure_id in enumerate(structure_ids):\n",
    "    protein = np.load('../data/voxelized data 14x14x17 2/' + structure_id + '_protein.npy', mmap_mode='r')\n",
    "    rna = np.load('../data/voxelized data 14x14x17 2/' + structure_id + '_rna_3D.npy', mmap_mode='r')\n",
    "\n",
    "    k = 0\n",
    "    pp_ = 0\n",
    "    while (np.sum(rna[k]) >= 100) and (k < len(rna)-1):\n",
    "        pp_ +=1\n",
    "        k +=1\n",
    "\n",
    "    if j <= num_test:\n",
    "        X_test.extend(protein[:pp_, :, :, :, :3])\n",
    "        Y_test.extend(rna[:pp_])\n",
    "        num_aa_test +=pp_\n",
    "        num_pp +=pp_\n",
    "\n",
    "    else:\n",
    "        X_train.extend(protein[:pp_, :, :, :, :3])\n",
    "        Y_train.extend(rna[:pp_])\n",
    "        num_aa_train +=pp_\n",
    "\n",
    "    p_= 0 \n",
    "    while (100 > np.sum(rna[k]) > 0)  and (k < len(rna)-1):\n",
    "        if (pos_test > 0):\n",
    "            p_ +=1\n",
    "            pos_test -=1\n",
    "        k +=1\n",
    "\n",
    "\n",
    "    X_test.extend(protein[pp_:(pp_+p_), :, :, :, :3])\n",
    "    Y_test.extend(rna[pp_:(pp_+p_)])\n",
    "    num_aa_test +=p_\n",
    "    num_p +=p_\n",
    "\n",
    "    n_= 0\n",
    "    while (np.sum(rna[k]) == 0) and (neg_test > 0) and (k < len(rna)-1):\n",
    "        n_ +=1\n",
    "        neg_test -=1\n",
    "        k +=1\n",
    "\n",
    "    X_test.extend(protein[(pp_+p_):(pp_+p_+n_), :, :, :, :3])\n",
    "    Y_test.extend(rna[(pp_+p_):(pp_+p_+n_)])\n",
    "    num_aa_test +=n_\n",
    "    num_n +=n_\n",
    "\n",
    "\n",
    "Y_test_ = np.array(list(map(lambda x:np.sum(np.sum(x, axis=0), axis=0), Y_test)))\n",
    "Y_test_[Y_test_ < 25] = 0\n",
    "Y_test_[Y_test_ >= 25] = 1\n",
    "\n",
    "\n",
    "print(Y_test_.shape)\n",
    "\n",
    "n_steps_train = int(num_aa_train/1024) \n",
    "n_steps_test = int(num_aa_test/1024)\n",
    "\n",
    "print(num_aa_train, num_aa_test)\n",
    "\n",
    "print(pp_train, pp_test, pos_test, neg_test)\n",
    "print(num_pp, num_p, num_n)\n",
    "\n",
    "generator_train = generator(X_train, Y_train, 1024, True)\n",
    "generator_validation = generator(X_test, Y_test, 1024, True)\n",
    "generator_test = generator(X_test, Y_test, 1024, False)\n",
    "\n",
    "ins = tf.keras.layers.Input((14, 14, 17, 3))\n",
    "con1 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', activation='relu')(ins)\n",
    "con2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con1)\n",
    "con3 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con2)\n",
    "maxp1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con3)\n",
    "con4 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp1)\n",
    "con5 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con4)\n",
    "con6 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con5)\n",
    "maxp2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con6)\n",
    "con7 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp2)\n",
    "con8 = tf.keras.layers.Conv3D(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu')(con7)\n",
    "con9 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='same', activation='relu')(con8)\n",
    "maxp3 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con9)\n",
    "batch = tf.keras.layers.BatchNormalization()(maxp3)\n",
    "flat = tf.keras.layers.Flatten()(batch)\n",
    "dens2 = tf.keras.layers.Dense(units=256, activation='relu')(flat)\n",
    "drop2 = tf.keras.layers.Dropout(0.6)(dens2)\n",
    "outs = tf.keras.layers.Dense(units=17, activation='sigmoid')(drop2)\n",
    "model = tf.keras.models.Model(inputs=ins, outputs=outs)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# checkpoint\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, mode='min', min_delta=0.0001)\n",
    "# mc = tf.keras.callbacks.ModelCheckpoint(\"weights_best.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "# model.fit(X_train, Y_train_f, validation_split=0.33, epochs=1, batch_size=200, callbacks=callbacks_list, verbose=0)\n",
    "history = model.fit_generator(generator_train, steps_per_epoch=n_steps_train, epochs=500, \n",
    "                    validation_data = generator_validation, validation_steps=n_steps_test, callbacks=[es], verbose=1)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss')\n",
    "\n",
    "\n",
    "# model_best = model\n",
    "# model_best.load_weights(\"weights_best.hdf5\")\n",
    "# print(model.evaluate(X_test, Y_test, verbose=0, batch_size=100))\n",
    "# model_best.save('model_cnn_15_2.h5')\n",
    "# Y_pred = model_best.predict(X_test, batch_size=200)\n",
    "Y_pred_ = model.predict_generator(generator_test, steps=n_steps_test)\n",
    "# print(Y_pred.shape)\n",
    "# Y_pred_ = np.array([Y_pred[i].reshape((2,2,17)) for i in range(Y_pred.shape[0])])\n",
    "\n",
    "#CNN\n",
    "Y_pred_prob = Y_pred_\n",
    "Y_pred_[Y_pred_ >= 0.5] = 1\n",
    "Y_pred_[Y_pred_ < 0.5] = 0\n",
    "\n",
    "print(Y_pred_.shape)\n",
    "print(Y_test_.shape)\n",
    "Y_test_ = Y_test_[:Y_pred_.shape[0]]\n",
    "\n",
    "\n",
    "print('CNN: \\n')\n",
    "\n",
    "confusion_matrix = [sklearn.metrics.confusion_matrix(Y_test_[:,i], Y_pred_[:, i]) for i in range(17)]\n",
    "accuracy = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix]\n",
    "auc = [sklearn.metrics.roc_auc_score(Y_test_[:,i], Y_pred_prob[:,i]) for i in range(17)]\n",
    "\n",
    "for q in range(17):\n",
    "    print(f'level {q+1}')\n",
    "    print(confusion_matrix[q], np.round(accuracy[q], 2), np.round(auc[q], 2))\n",
    "\n",
    "# baseline model\n",
    "# predict all zeros; at least 50% correct predictions because there are 1/2 of negative examples\n",
    "Y_pred_base = np.zeros(Y_test_.shape)\n",
    "\n",
    "# po = np.sum(Y_train, axis=0)/Y_train.shape[0]\n",
    "# po[po >= 0.5] = 1\n",
    "# po[po < 0.5] = 0\n",
    "# Y_pred_base = np.tile(po, (Y_test.shape[0],1))\n",
    "\n",
    "print(Y_pred_base.shape)\n",
    "print(f'\\n BASELINE MODEL: \\n')\n",
    "\n",
    "confusion_matrix_base = [sklearn.metrics.confusion_matrix(Y_test_[:,i], Y_pred_base[:,i]) for i in range(17)]\n",
    "accuracy_base = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_base]\n",
    "auc_base = [sklearn.metrics.roc_auc_score(Y_test_[:, i], Y_pred_base[:,i]) for i in range(17)]\n",
    "\n",
    "for q in range(17):\n",
    "    print(f'level {q+1}')\n",
    "    print(confusion_matrix_base[q], np.round(accuracy_base[q], 2), np.round(auc_base[q], 2))\n",
    "\n",
    "#random model\n",
    "Y_pred_random = np.random.random(Y_test_.shape)\n",
    "Y_pred_random[Y_pred_random >= 0.5] = 1\n",
    "Y_pred_random[Y_pred_random < 0.5] = 0\n",
    "\n",
    "print(f'\\n RANDOM MODEL: \\n')\n",
    "\n",
    "confusion_matrix_random = [sklearn.metrics.confusion_matrix(Y_test_[:,i], Y_pred_random[:,i]) for i in range(17)]\n",
    "accuracy_random = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_random]\n",
    "auc_random = [sklearn.metrics.roc_auc_score(Y_test_[:,i], Y_pred_random[:,i]) for i in range(17)]\n",
    "\n",
    "for q in range(17):\n",
    "    print(f'level {q+1}')\n",
    "    print(confusion_matrix_random[q], np.round(accuracy_random[q], 2), np.round(auc_random[q], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
