{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "83862 44057\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 6, 6, 6, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 6, 6, 6, 64)       5248      \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 6, 6, 6, 32)       55328     \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 6, 6, 6, 32)       27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 3, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 3, 3, 3, 32)       27680     \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 3, 3, 3, 16)       13840     \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 3, 3, 3, 16)       6928      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 1, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_33 (Conv3D)           (None, 1, 1, 1, 16)       6928      \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 1, 1, 1, 8)        3464      \n",
      "_________________________________________________________________\n",
      "conv3d_35 (Conv3D)           (None, 1, 1, 1, 4)        868       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 1, 4)        16        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1280      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 155,428\n",
      "Trainable params: 155,420\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "209/209 [==============================] - 18s 87ms/step - loss: 0.6920 - acc: 0.7215\n",
      "Epoch 2/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.6857 - acc: 0.6990\n",
      "Epoch 3/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.6732 - acc: 0.6856\n",
      "Epoch 4/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.6536 - acc: 0.7060\n",
      "Epoch 5/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.6386 - acc: 0.7423 1s - loss: 0\n",
      "Epoch 6/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.6264 - acc: 0.7692\n",
      "Epoch 7/100\n",
      "209/209 [==============================] - 15s 71ms/step - loss: 0.6149 - acc: 0.7889\n",
      "Epoch 8/100\n",
      "209/209 [==============================] - 15s 71ms/step - loss: 0.6042 - acc: 0.8030\n",
      "Epoch 9/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.5938 - acc: 0.8137\n",
      "Epoch 10/100\n",
      "209/209 [==============================] - 17s 80ms/step - loss: 0.5847 - acc: 0.8201\n",
      "Epoch 11/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.5767 - acc: 0.8232\n",
      "Epoch 12/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.5682 - acc: 0.8269\n",
      "Epoch 13/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.5600 - acc: 0.8296\n",
      "Epoch 14/100\n",
      "209/209 [==============================] - 16s 79ms/step - loss: 0.5526 - acc: 0.8313\n",
      "Epoch 15/100\n",
      "209/209 [==============================] - 17s 80ms/step - loss: 0.5454 - acc: 0.8327\n",
      "Epoch 16/100\n",
      "209/209 [==============================] - 17s 82ms/step - loss: 0.5386 - acc: 0.8340\n",
      "Epoch 17/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.5327 - acc: 0.8339\n",
      "Epoch 18/100\n",
      "209/209 [==============================] - 17s 81ms/step - loss: 0.5263 - acc: 0.8346\n",
      "Epoch 19/100\n",
      "209/209 [==============================] - 17s 80ms/step - loss: 0.5202 - acc: 0.8354\n",
      "Epoch 20/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.5145 - acc: 0.8362\n",
      "Epoch 21/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.5090 - acc: 0.8371\n",
      "Epoch 22/100\n",
      "209/209 [==============================] - 14s 69ms/step - loss: 0.5043 - acc: 0.8377\n",
      "Epoch 23/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.5011 - acc: 0.8368\n",
      "Epoch 24/100\n",
      "209/209 [==============================] - 16s 78ms/step - loss: 0.4983 - acc: 0.8359\n",
      "Epoch 25/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4946 - acc: 0.8360\n",
      "Epoch 26/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4909 - acc: 0.8365\n",
      "Epoch 27/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4887 - acc: 0.8361\n",
      "Epoch 28/100\n",
      "209/209 [==============================] - 16s 78ms/step - loss: 0.4858 - acc: 0.8363\n",
      "Epoch 29/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4831 - acc: 0.8365\n",
      "Epoch 30/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4808 - acc: 0.8363\n",
      "Epoch 31/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4794 - acc: 0.8359\n",
      "Epoch 32/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4772 - acc: 0.8359\n",
      "Epoch 33/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4753 - acc: 0.8359\n",
      "Epoch 34/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4736 - acc: 0.8359\n",
      "Epoch 35/100\n",
      "209/209 [==============================] - 16s 78ms/step - loss: 0.4719 - acc: 0.8359\n",
      "Epoch 36/100\n",
      "209/209 [==============================] - 16s 79ms/step - loss: 0.4705 - acc: 0.8360\n",
      "Epoch 37/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4694 - acc: 0.8360\n",
      "Epoch 38/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4680 - acc: 0.8360\n",
      "Epoch 39/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4668 - acc: 0.8362\n",
      "Epoch 40/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4657 - acc: 0.8365 2s \n",
      "Epoch 41/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4644 - acc: 0.8367\n",
      "Epoch 42/100\n",
      "209/209 [==============================] - 16s 78ms/step - loss: 0.4631 - acc: 0.8370\n",
      "Epoch 43/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4619 - acc: 0.8374\n",
      "Epoch 44/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4606 - acc: 0.8378\n",
      "Epoch 45/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4592 - acc: 0.8384\n",
      "Epoch 46/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4586 - acc: 0.8387\n",
      "Epoch 47/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4614 - acc: 0.8360\n",
      "Epoch 48/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4608 - acc: 0.8361\n",
      "Epoch 49/100\n",
      "209/209 [==============================] - 15s 71ms/step - loss: 0.4592 - acc: 0.8366\n",
      "Epoch 50/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4579 - acc: 0.8371\n",
      "Epoch 51/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4567 - acc: 0.8376\n",
      "Epoch 52/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4585 - acc: 0.8362\n",
      "Epoch 53/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4579 - acc: 0.8362\n",
      "Epoch 54/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4566 - acc: 0.8369\n",
      "Epoch 55/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4568 - acc: 0.8364\n",
      "Epoch 56/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4563 - acc: 0.8365\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4561 - acc: 0.8362\n",
      "Epoch 58/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4557 - acc: 0.8365\n",
      "Epoch 59/100\n",
      "209/209 [==============================] - 16s 78ms/step - loss: 0.4551 - acc: 0.8366\n",
      "Epoch 60/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4559 - acc: 0.8360\n",
      "Epoch 61/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4555 - acc: 0.8361\n",
      "Epoch 62/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4538 - acc: 0.8368 0s - loss: 0.4535 - acc:\n",
      "Epoch 63/100\n",
      "209/209 [==============================] - 15s 70ms/step - loss: 0.4520 - acc: 0.8375\n",
      "Epoch 64/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4532 - acc: 0.8365\n",
      "Epoch 65/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4532 - acc: 0.8366\n",
      "Epoch 66/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4532 - acc: 0.8363\n",
      "Epoch 67/100\n",
      "209/209 [==============================] - 15s 71ms/step - loss: 0.4534 - acc: 0.8361\n",
      "Epoch 68/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4521 - acc: 0.8368\n",
      "Epoch 69/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4509 - acc: 0.8375\n",
      "Epoch 70/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4494 - acc: 0.8383\n",
      "Epoch 71/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4504 - acc: 0.8375\n",
      "Epoch 72/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4514 - acc: 0.8365\n",
      "Epoch 73/100\n",
      "209/209 [==============================] - 16s 77ms/step - loss: 0.4519 - acc: 0.8360\n",
      "Epoch 74/100\n",
      "209/209 [==============================] - 16s 79ms/step - loss: 0.4505 - acc: 0.8369\n",
      "Epoch 75/100\n",
      "209/209 [==============================] - 15s 71ms/step - loss: 0.4511 - acc: 0.8364\n",
      "Epoch 76/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4506 - acc: 0.8365\n",
      "Epoch 77/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4501 - acc: 0.8366\n",
      "Epoch 78/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4502 - acc: 0.8364\n",
      "Epoch 79/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4504 - acc: 0.8363\n",
      "Epoch 80/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4503 - acc: 0.8360\n",
      "Epoch 81/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4501 - acc: 0.8360\n",
      "Epoch 82/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4485 - acc: 0.8366\n",
      "Epoch 83/100\n",
      "209/209 [==============================] - 15s 70ms/step - loss: 0.4471 - acc: 0.8374 0s - loss: 0.4439 - a\n",
      "Epoch 84/100\n",
      "209/209 [==============================] - 15s 71ms/step - loss: 0.4473 - acc: 0.8371\n",
      "Epoch 85/100\n",
      "209/209 [==============================] - 15s 70ms/step - loss: 0.4484 - acc: 0.8362\n",
      "Epoch 86/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4480 - acc: 0.8366\n",
      "Epoch 87/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4487 - acc: 0.8361\n",
      "Epoch 88/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4475 - acc: 0.8367\n",
      "Epoch 89/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4463 - acc: 0.8374 1s - loss: \n",
      "Epoch 90/100\n",
      "209/209 [==============================] - 16s 76ms/step - loss: 0.4442 - acc: 0.8385\n",
      "Epoch 91/100\n",
      "209/209 [==============================] - 16s 78ms/step - loss: 0.4453 - acc: 0.8383\n",
      "Epoch 92/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4469 - acc: 0.8363 1s - loss: 0.4\n",
      "Epoch 93/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4470 - acc: 0.8363\n",
      "Epoch 94/100\n",
      "209/209 [==============================] - 15s 74ms/step - loss: 0.4447 - acc: 0.8375\n",
      "Epoch 95/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4446 - acc: 0.8376\n",
      "Epoch 96/100\n",
      "209/209 [==============================] - 15s 72ms/step - loss: 0.4462 - acc: 0.8361\n",
      "Epoch 97/100\n",
      "209/209 [==============================] - 15s 73ms/step - loss: 0.4459 - acc: 0.8361\n",
      "Epoch 98/100\n",
      "209/209 [==============================] - 16s 74ms/step - loss: 0.4450 - acc: 0.8368\n",
      "Epoch 99/100\n",
      "209/209 [==============================] - 16s 75ms/step - loss: 0.4432 - acc: 0.8376\n",
      "Epoch 100/100\n",
      "209/209 [==============================] - 17s 79ms/step - loss: 0.4418 - acc: 0.8384\n",
      "(44000, 24)\n",
      "(44000, 2, 2, 6)\n",
      "(44057, 2, 2, 6)\n",
      "CNN: \n",
      "\n",
      "level 0\n",
      "[[38788     0]\n",
      " [ 5212     0]] 0.88 0.5\n",
      "[[38651     0]\n",
      " [ 5349     0]] 0.88 0.5\n",
      "[[39025     0]\n",
      " [ 4975     0]] 0.89 0.5\n",
      "[[38741     0]\n",
      " [ 5259     0]] 0.88 0.5\n",
      "level 1\n",
      "[[38201     0]\n",
      " [ 5799     0]] 0.87 0.5\n",
      "[[38196     0]\n",
      " [ 5804     0]] 0.87 0.5\n",
      "[[38636     0]\n",
      " [ 5364     0]] 0.88 0.5\n",
      "[[38392     0]\n",
      " [ 5608     0]] 0.87 0.5\n",
      "level 2\n",
      "[[37459     0]\n",
      " [ 6541     0]] 0.85 0.5\n",
      "[[37402     0]\n",
      " [ 6598     0]] 0.85 0.5\n",
      "[[37928     0]\n",
      " [ 6072     0]] 0.86 0.5\n",
      "[[37431     0]\n",
      " [ 6569     0]] 0.85 0.5\n",
      "level 3\n",
      "[[35945     0]\n",
      " [ 8055     0]] 0.82 0.5\n",
      "[[36138     0]\n",
      " [ 7862     0]] 0.82 0.5\n",
      "[[36519     0]\n",
      " [ 7481     0]] 0.83 0.5\n",
      "[[36019     0]\n",
      " [ 7981     0]] 0.82 0.5\n",
      "level 4\n",
      "[[34785     0]\n",
      " [ 9215     0]] 0.79 0.5\n",
      "[[34738     0]\n",
      " [ 9262     0]] 0.79 0.5\n",
      "[[35189     0]\n",
      " [ 8811     0]] 0.8 0.5\n",
      "[[34618     0]\n",
      " [ 9382     0]] 0.79 0.5\n",
      "level 5\n",
      "[[33945     0]\n",
      " [10055     0]] 0.77 0.5\n",
      "[[33640     0]\n",
      " [10360     0]] 0.76 0.5\n",
      "[[34176     0]\n",
      " [ 9824     0]] 0.78 0.5\n",
      "[[33677     0]\n",
      " [10323     0]] 0.77 0.5\n",
      "(44000, 2, 2, 6)\n",
      "\n",
      " BASELINE MODEL: \n",
      "\n",
      "level 0\n",
      "[[38788     0]\n",
      " [ 5212     0]] 0.88 0.5\n",
      "[[38651     0]\n",
      " [ 5349     0]] 0.88 0.5\n",
      "[[39025     0]\n",
      " [ 4975     0]] 0.89 0.5\n",
      "[[38741     0]\n",
      " [ 5259     0]] 0.88 0.5\n",
      "level 1\n",
      "[[38201     0]\n",
      " [ 5799     0]] 0.87 0.5\n",
      "[[38196     0]\n",
      " [ 5804     0]] 0.87 0.5\n",
      "[[38636     0]\n",
      " [ 5364     0]] 0.88 0.5\n",
      "[[38392     0]\n",
      " [ 5608     0]] 0.87 0.5\n",
      "level 2\n",
      "[[37459     0]\n",
      " [ 6541     0]] 0.85 0.5\n",
      "[[37402     0]\n",
      " [ 6598     0]] 0.85 0.5\n",
      "[[37928     0]\n",
      " [ 6072     0]] 0.86 0.5\n",
      "[[37431     0]\n",
      " [ 6569     0]] 0.85 0.5\n",
      "level 3\n",
      "[[35945     0]\n",
      " [ 8055     0]] 0.82 0.5\n",
      "[[36138     0]\n",
      " [ 7862     0]] 0.82 0.5\n",
      "[[36519     0]\n",
      " [ 7481     0]] 0.83 0.5\n",
      "[[36019     0]\n",
      " [ 7981     0]] 0.82 0.5\n",
      "level 4\n",
      "[[34785     0]\n",
      " [ 9215     0]] 0.79 0.5\n",
      "[[34738     0]\n",
      " [ 9262     0]] 0.79 0.5\n",
      "[[35189     0]\n",
      " [ 8811     0]] 0.8 0.5\n",
      "[[34618     0]\n",
      " [ 9382     0]] 0.79 0.5\n",
      "level 5\n",
      "[[33945     0]\n",
      " [10055     0]] 0.77 0.5\n",
      "[[33640     0]\n",
      " [10360     0]] 0.76 0.5\n",
      "[[34176     0]\n",
      " [ 9824     0]] 0.78 0.5\n",
      "[[33677     0]\n",
      " [10323     0]] 0.77 0.5\n",
      "\n",
      " RANDOM MODEL: \n",
      "\n",
      "level 0\n",
      "[[19250 19538]\n",
      " [ 2598  2614]] 0.5 0.5\n",
      "[[19352 19299]\n",
      " [ 2690  2659]] 0.5 0.5\n",
      "[[19498 19527]\n",
      " [ 2545  2430]] 0.5 0.49\n",
      "[[19352 19389]\n",
      " [ 2638  2621]] 0.5 0.5\n",
      "level 1\n",
      "[[19158 19043]\n",
      " [ 2900  2899]] 0.5 0.5\n",
      "[[19194 19002]\n",
      " [ 2841  2963]] 0.5 0.51\n",
      "[[19389 19247]\n",
      " [ 2712  2652]] 0.5 0.5\n",
      "[[19244 19148]\n",
      " [ 2780  2828]] 0.5 0.5\n",
      "level 2\n",
      "[[18604 18855]\n",
      " [ 3220  3321]] 0.5 0.5\n",
      "[[18753 18649]\n",
      " [ 3246  3352]] 0.5 0.5\n",
      "[[18988 18940]\n",
      " [ 3056  3016]] 0.5 0.5\n",
      "[[18808 18623]\n",
      " [ 3275  3294]] 0.5 0.5\n",
      "level 3\n",
      "[[17895 18050]\n",
      " [ 3994  4061]] 0.5 0.5\n",
      "[[18131 18007]\n",
      " [ 3939  3923]] 0.5 0.5\n",
      "[[18241 18278]\n",
      " [ 3704  3777]] 0.5 0.5\n",
      "[[18071 17948]\n",
      " [ 3991  3990]] 0.5 0.5\n",
      "level 4\n",
      "[[17566 17219]\n",
      " [ 4607  4608]] 0.5 0.5\n",
      "[[17503 17235]\n",
      " [ 4623  4639]] 0.5 0.5\n",
      "[[17621 17568]\n",
      " [ 4426  4385]] 0.5 0.5\n",
      "[[17141 17477]\n",
      " [ 4739  4643]] 0.5 0.5\n",
      "level 5\n",
      "[[16926 17019]\n",
      " [ 4984  5071]] 0.5 0.5\n",
      "[[16771 16869]\n",
      " [ 5159  5201]] 0.5 0.5\n",
      "[[17091 17085]\n",
      " [ 4879  4945]] 0.5 0.5\n",
      "[[16849 16828]\n",
      " [ 5166  5157]] 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "import random\n",
    "random.seed(7)\n",
    "\n",
    "\n",
    "def generator(X, Y, batch_size=32, train=True):\n",
    "    while True:\n",
    "        for offset in range(0, len(X), batch_size):\n",
    "            X_batch = np.stack(X[offset:offset+batch_size], axis=0)\n",
    "            Y_batch = np.stack(Y[offset:offset+batch_size], axis=0)\n",
    "\n",
    "            Y_batch_ = np.empty((Y_batch.shape[0], 2,2,6))\n",
    "            for m in range(Y_batch.shape[0]):\n",
    "                for i in range(6):\n",
    "                    Y_batch_[m, :,:,i] = [[np.sum(Y_batch[m, :3, :3, i]), np.sum(Y_batch[m, :3, 3:, i])], [np.sum(Y_batch[m, 3:, :3, i]), np.sum(Y_batch[m, 3:, 3:, i])]]\n",
    "            Y_batch_[Y_batch_ > 0] = 1\n",
    "\n",
    "            if train:\n",
    "                Y_f = np.array([Y_batch_[e].flatten() for e in range(Y_batch_.shape[0])])\n",
    "                yield (X_batch, Y_f)\n",
    "            else:\n",
    "                yield X_batch\n",
    "\n",
    "structure_ids = []\n",
    "for line in open('./structures lists/structures human.txt', 'r'):\n",
    "    line = line.strip('\\n')\n",
    "    structure_ids.append(line)\n",
    "# for line in open('./structures lists/structures ecoli.txt', 'r'):\n",
    "#     line = line.strip('\\n')\n",
    "#     structure_ids.append(line)\n",
    "structure_ids.remove('4pkd')\n",
    "structure_ids.remove('1a9n')\n",
    "structure_ids.remove('2adc')\n",
    "random.shuffle(structure_ids)\n",
    "print(len(structure_ids))\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "num_aa_train = 0\n",
    "num_aa_test = 0\n",
    "num_train = int(len(structure_ids)*0.7)\n",
    "for i, structure_id in enumerate(structure_ids):\n",
    "    protein = np.load('../data/voxelized data 6x6x6/' + structure_id + '_protein.npy', mmap_mode='r')\n",
    "    rna = np.load('../data/voxelized data 6x6x6/' + structure_id + '_rna_3D.npy', mmap_mode='r')\n",
    "    na = 0\n",
    "    pos = 0\n",
    "    while (np.sum(rna[na]) > 0) and (na < len(rna)-1):\n",
    "        pos +=1\n",
    "        na +=1\n",
    "    \n",
    "\n",
    "    if i <= num_train:\n",
    "        if pos > len(rna)/2:\n",
    "            X_train.extend(protein[:, :, :, :, :3])\n",
    "            Y_train.extend(rna)\n",
    "            num_aa_train +=len(rna)\n",
    "        else:\n",
    "            X_train.extend(protein[:pos, :, :, :, :3])\n",
    "            X_train.extend(protein[-pos:, :, :, :, :3])\n",
    "            Y_train.extend(rna[:pos])\n",
    "            Y_train.extend(rna[-pos:])\n",
    "            num_aa_train +=2*pos\n",
    "    else:\n",
    "        if pos > len(rna)/2:\n",
    "            X_test.extend(protein[:, :, :, :, :3])\n",
    "            Y_test.extend(rna)\n",
    "            num_aa_test +=len(rna)\n",
    "        else:\n",
    "            X_test.extend(protein[:pos, :, :, :, :3])\n",
    "            X_test.extend(protein[-pos:, :, :, :, :3])\n",
    "            Y_test.extend(rna[:pos])\n",
    "            Y_test.extend(rna[-pos:])\n",
    "            num_aa_test +=2*pos\n",
    "\n",
    "Y_test = np.stack(Y_test, axis=0)\n",
    "Y_test_ = np.empty((len(Y_test), 2,2,6))\n",
    "for m in range(len(Y_test)):\n",
    "    for i in range(6):\n",
    "        Y_test_[m, :,:,i] = [[np.sum(Y_test[m, :3, :3, i]), np.sum(Y_test[m, :3, 3:, i])], [np.sum(Y_test[m, 3:, :3, i]), np.sum(Y_test[m, 3:, 3:, i])]]\n",
    "Y_test_[Y_test_ > 0] = 1\n",
    "   \n",
    "n_steps_train = int(num_aa_train/400) \n",
    "n_steps_test = int(num_aa_test/400)\n",
    "\n",
    "print(num_aa_train, num_aa_test)\n",
    "\n",
    "generator_train = generator(X_train, Y_train, 400, True)\n",
    "generator_test = generator(X_test, Y_test, 400, False)\n",
    "\n",
    "ins = tf.keras.layers.Input((6, 6, 6, 3))\n",
    "con1 = tf.keras.layers.Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', activation='relu')(ins)\n",
    "con2 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con1)\n",
    "con3 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(con2)\n",
    "maxp1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con3)\n",
    "con4 = tf.keras.layers.Conv3D(filters=32, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp1)\n",
    "con5 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con4)\n",
    "con6 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(con5)\n",
    "maxp2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con6)\n",
    "con7 = tf.keras.layers.Conv3D(filters=16, kernel_size=(3, 3, 3), padding='same', activation='relu')(maxp2)\n",
    "con8 = tf.keras.layers.Conv3D(filters=8, kernel_size=(3, 3, 3), padding='same', activation='relu')(con7)\n",
    "con9 = tf.keras.layers.Conv3D(filters=4, kernel_size=(3, 3, 3), padding='same', activation='relu')(con8)\n",
    "# maxp3 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2))(con9)\n",
    "batch = tf.keras.layers.BatchNormalization()(con9)\n",
    "flat = tf.keras.layers.Flatten()(batch)\n",
    "dens2 = tf.keras.layers.Dense(units=256, activation='relu')(flat)\n",
    "drop2 = tf.keras.layers.Dropout(0.6)(dens2)\n",
    "outs = tf.keras.layers.Dense(units=24, activation='sigmoid')(drop2)\n",
    "model = tf.keras.models.Model(inputs=ins, outputs=outs)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.00001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# checkpoint\n",
    "# filepath=\"weights_best.hdf5\"\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# model.fit(X_train, Y_train_f, validation_split=0.33, epochs=1, batch_size=200, callbacks=callbacks_list, verbose=0)\n",
    "model.fit_generator(generator_train, steps_per_epoch=n_steps_train, epochs=100, callbacks=None, verbose=1, max_queue_size=2)\n",
    "\n",
    "# model_best = model\n",
    "# model_best.load_weights(\"weights_best.hdf5\")\n",
    "# print(model.evaluate(X_test, Y_test, verbose=0, batch_size=100))\n",
    "# model_best.save('model_cnn_15_2.h5')\n",
    "# Y_pred = model_best.predict(X_test, batch_size=200)\n",
    "Y_pred = model.predict_generator(generator_test, steps=n_steps_test)\n",
    "print(Y_pred.shape)\n",
    "Y_pred_ = np.array([Y_pred[i].reshape((2,2,6)) for i in range(Y_pred.shape[0])])\n",
    "\n",
    "#CNN\n",
    "Y_pred_[Y_pred_ >= 0.5] = 1\n",
    "Y_pred_[Y_pred_ < 0.5] = 0\n",
    "\n",
    "print(Y_pred_.shape)\n",
    "print(Y_test_.shape)\n",
    "Y_test_ = Y_test_[:Y_pred_.shape[0]]\n",
    "\n",
    "print('CNN: \\n')\n",
    "for i in range(6):\n",
    "    confusion_matrix = [sklearn.metrics.confusion_matrix(Y_test_[:,l , c, i], Y_pred_[:,l , c, i]) for l in range(2) for c in range(2)]\n",
    "    accuracy = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix]\n",
    "    auc = [sklearn.metrics.roc_auc_score(Y_test_[:,l , c, i], Y_pred_[:,l , c, i]) for l in range(2) for c in range(2)]\n",
    "\n",
    "    print(f'level {i}')\n",
    "    for q in range(len(confusion_matrix)):\n",
    "        print(confusion_matrix[q], np.round(accuracy[q], 2), np.round(auc[q], 2))\n",
    "\n",
    "# baseline model\n",
    "# predict all zeros; at least 50% correct predictions because there are 1/2 of negative examples\n",
    "Y_pred_base = np.zeros(Y_test_.shape)\n",
    "\n",
    "# po = np.sum(Y_train, axis=0)/Y_train.shape[0]\n",
    "# po[po >= 0.5] = 1\n",
    "# po[po < 0.5] = 0\n",
    "# Y_pred_base = np.tile(po, (Y_test.shape[0],1))\n",
    "\n",
    "Y_pred_base[Y_pred_base >= 0.5] = 1\n",
    "Y_pred_base[Y_pred_base < 0.5] = 0\n",
    "print(Y_pred_base.shape)\n",
    "print(f'\\n BASELINE MODEL: \\n')\n",
    "for i in range(6):\n",
    "    confusion_matrix_base = [sklearn.metrics.confusion_matrix(Y_test_[:,l, c, i], Y_pred_base[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "    accuracy_base = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_base]\n",
    "    auc_base = [sklearn.metrics.roc_auc_score(Y_test_[:,l, c, i], Y_pred_base[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "    \n",
    "    print(f'level {i}')\n",
    "    for q in range(len(confusion_matrix_base)):\n",
    "        print(confusion_matrix_base[q], np.round(accuracy_base[q], 2), np.round(auc_base[q], 2))\n",
    "\n",
    "#random model\n",
    "Y_pred_random = np.random.random(Y_test_.shape)\n",
    "Y_pred_random[Y_pred_random >= 0.5] = 1\n",
    "Y_pred_random[Y_pred_random < 0.5] = 0\n",
    "\n",
    "print(f'\\n RANDOM MODEL: \\n')\n",
    "for i in range(6):\n",
    "    confusion_matrix_random = [sklearn.metrics.confusion_matrix(Y_test_[:,l, c, i], Y_pred_random[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "    accuracy_random = [np.sum(np.trace(cm))/np.sum(cm) for cm in confusion_matrix_random]\n",
    "    auc_random = [sklearn.metrics.roc_auc_score(Y_test_[:,l, c, i], Y_pred_random[:,l, c, i]) for l in range(2) for c in range(2)]\n",
    "\n",
    "    print(f'level {i}')\n",
    "    for q in range(len(confusion_matrix_random)):\n",
    "        print(confusion_matrix_random[q], np.round(accuracy_random[q], 2), np.round(auc_random[q], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
